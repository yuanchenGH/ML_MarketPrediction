{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import time\n",
    "torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#setup data\n",
    "\n",
    "#define risk free rate(rfr) as the three month treasure yield (DGS3MO)\n",
    "rfr = np.array((5244,1))\n",
    "#define term spread as 10 year treasure interest(DGS10) minus 1 year treasure interest(DGS1)\n",
    "ts = np.array((5244,1))\n",
    "#define default spread as the yield gap between AAA(DAAA) and BBB(DBAA) grade bonds\n",
    "ds = np.array((5244,1))\n",
    "ones = np.ones((5243,1))[:,0]\n",
    "\n",
    "data1 = pd.read_csv('spread.csv')\n",
    "data2 = pd.read_csv('StockMarket.csv')\n",
    "data = pd.merge(data1, data2, on='Date')\n",
    "rfr = data['DGS3MO']\n",
    "ds = data['DGS10'] - data['DGS1']\n",
    "ts = data['DBAA'] - data['DAAA']\n",
    "# A = np.stack((rfr, ds, ts, ones), axis = 1)\n",
    "\n",
    "rfr2=np.zeros((5243,))\n",
    "ds2=np.zeros((5243,))\n",
    "ts2=np.zeros((5243,))\n",
    "for i in range(5243):\n",
    "    rfr2[i] = rfr[i+1]-rfr[i]\n",
    "    ds2[i] = ds[i+1]-ds[i]\n",
    "    ts2[i] = ts[i+1]-ts[i]\n",
    "\n",
    "#the yield of three major index: Dow Jones, SP 500 and Nasdaq\n",
    "B_raw = np.stack((data['DJIA'], data['SP500'], data['NASDAQ']), axis = 1)\n",
    "#Labeled as -1 if the market loss the next day, +1 otherwise \n",
    "B = np.zeros((5244, 3))\n",
    "for i in range(5244):\n",
    "    for j in range(3):\n",
    "        B[i][j] = -1 if B_raw[i][j] < 0 else 1\n",
    "\n",
    "A = np.stack((rfr[1:], ds[1:], ts[1:], rfr2, ds2, ts2, B_raw[:5243,0], B_raw[:5243,1], B_raw[:5243,2], ones), axis = 1)\n",
    "# A = np.stack((rfr2, ds2, ts2, ones), axis = 1)\n",
    "A = preprocessing.normalize(A)\n",
    "\n",
    "#delete first label since there is no previous day data to predict\n",
    "B= np.delete(B, 0, 0)\n",
    "n = A.shape[1]#number of feature\n",
    "nodes = 7#number of nodes in each layer\n",
    "# print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#module\n",
    "class binaryClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(binaryClassification, self).__init__()\n",
    "        self.l1 = nn.Linear(n, nodes)\n",
    "#         self.l2 = nn.Linear(nodes, nodes)\n",
    "#         self.l3 = nn.Linear(nodes, nodes)\n",
    "#         self.l4 = nn.Linear(nodes, nodes)\n",
    "        self.l5 = nn.Linear(nodes, 3)\n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        x = F.relu(self.l1(inputs))\n",
    "#         x = F.relu(self.l2(x))\n",
    "#         x = F.relu(self.l3(x))\n",
    "#         x = F.relu(self.l4(x))\n",
    "        x = self.l5(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom loss function\n",
    "# def HingeLoss(my_outputs, my_labels):\n",
    "#     #specifying the batch size\n",
    "#     size = my_outputs.size()[0] \n",
    "#     hingeloss = torch.zeros([size, 3], requires_grad = True)\n",
    "#     my_outputs = torch.sign(my_outputs)\n",
    "# #     for k in range(size):\n",
    "# #         for l in range(3):\n",
    "# #             hingeloss[k][l] = max(0, 1 - my_outputs[k][l]*my_labels[k][l])\n",
    "# #     for k in range(3):\n",
    "# #         hingeloss[:, k] = torch.nn.Threshold(0, 0)(1- torch.dot(my_outputs[:,k], my_labels[:,k]))\n",
    "#     v = torch.ones([size, 3])\n",
    "#     hingeloss = my_outputs@my_labels\n",
    "\n",
    "#     #returning the results\n",
    "# #     return torch.sum(hingeloss) / size\n",
    "#     return hingeloss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = A\n",
    "Y = B\n",
    "\n",
    "sqer1 = np.zeros((10))\n",
    "er_rate1 = np.zeros((10))\n",
    "sqer2 = np.zeros((10))\n",
    "er_rate2 = np.zeros((10))\n",
    "sqer3 = np.zeros((10,))\n",
    "er_rate3 = np.zeros((10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8700, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "tensor(0.8695, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "tensor(0.8778, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "tensor(0.8975, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "tensor(0.8995, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "tensor(0.8824, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "tensor(0.8716, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "tensor(0.8731, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "tensor(0.8992, device='cuda:0', grad_fn=<L1LossBackward>)\n",
      "tensor(0.8878, device='cuda:0', grad_fn=<L1LossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#10-fold CV\n",
    "\n",
    "for j in range(10):\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, shuffle = True, random_state=i)\n",
    "    X_train_tensor = torch.from_numpy(X_train).float().cuda()\n",
    "    Y_train_tensor = torch.from_numpy(Y_train).float().cuda()\n",
    "    X_test_tensor = torch.from_numpy(X_test).float().cuda()\n",
    "    Y_test_tensor = torch.from_numpy(Y_test).float().cuda()\n",
    "    \n",
    "    epochs = 6000\n",
    "    LEARNING_RATE = 0.001\n",
    "\n",
    "    model = binaryClassification()\n",
    "    model.cuda()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
    "\n",
    "#     tic = time.perf_counter()\n",
    "    model.train()\n",
    "    for i in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        Y_pred = model(X_train_tensor)\n",
    "    #     Y_pred = torch.sign(Y_pred)\n",
    "        loss = nn.L1Loss()(Y_pred, Y_train_tensor)\n",
    "#         loss = HingeLoss(Y_pred, Y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         print(loss)\n",
    "#     toc = time.perf_counter()\n",
    "#     print(toc - tic)\n",
    "    print(loss)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        Y_test_pred = model(X_test_tensor)\n",
    "        Y_test_pred = torch.sign(Y_test_pred)\n",
    "        er = sum(abs(Y_test_pred - Y_test_tensor))\n",
    "#         print(er / (Y_test.shape[0] * 2))\n",
    "        sqer1[j] = torch.norm((Y_test_pred[:,0] - Y_test_tensor[:,0]))\n",
    "        er_rate1[j] = er[0] / (Y_test.shape[0] * 2)\n",
    "        sqer2[j] = torch.norm((Y_test_pred[:,1] - Y_test_tensor[:,1]))\n",
    "        er_rate2[j] = er[1] / (Y_test.shape[0] * 2)\n",
    "        sqer3[j] = torch.norm((Y_test_pred[:,2] - Y_test_tensor[:,2]))\n",
    "        er_rate3[j] = er[2] / (Y_test.shape[0] * 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.055 0.397\n",
      "0.0553 0.402\n",
      "0.0554 0.403\n"
     ]
    }
   ],
   "source": [
    "print(np.round(sqer1.mean() / Y_test.shape[0], 4), np.round(er_rate1.mean(), 3))\n",
    "print(np.round(sqer2.mean() / Y_test.shape[0], 4), np.round(er_rate2.mean(), 3))\n",
    "print(np.round(sqer3.mean() / Y_test.shape[0], 4), np.round(er_rate3.mean(), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
