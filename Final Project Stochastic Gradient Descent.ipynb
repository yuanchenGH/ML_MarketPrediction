{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#setup data\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#define risk free rate(rfr) as the three month treasure yield (DGS3MO)\n",
    "rfr = np.array((5244,1))\n",
    "#define term spread as 10 year treasure interest(DGS10) minus 1 year treasure interest(DGS1)\n",
    "ts = np.array((5244,1))\n",
    "#define default spread as the yield gap between AAA(DAAA) and BBB(DBAA) grade bonds\n",
    "ds = np.array((5244,1))\n",
    "ones = np.ones((5244,1))[:,0]\n",
    "\n",
    "data1 = pd.read_csv('spread.csv')\n",
    "data2 = pd.read_csv('StockMarket.csv')\n",
    "data = pd.merge(data1, data2, on='Date')\n",
    "rfr = data['DGS3MO']\n",
    "ds = data['DGS10'] - data['DGS1']\n",
    "ts = data['DAAA'] - data['DBAA']\n",
    "# print(rfr.shape)\n",
    "# print(ds.shape)\n",
    "# print(ts.shape)\n",
    "# print(ones.shape)\n",
    "A = np.stack((rfr, ds, ts, ones), axis = 1)\n",
    "#delete the last data since there is no label for the next day\n",
    "A = np.delete(A, 5243, 0)\n",
    "# print(data)\n",
    "\n",
    "#the yield of three major index: Dow Jones, SP 500 and Nasdaq\n",
    "B_raw = np.stack((data['DJIA'], data['SP500'], data['NASDAQ']), axis = 1)\n",
    "#Labeled as -1 if the market loss the next day, +1 otherwise \n",
    "B = np.zeros((5244, 3))\n",
    "for i in range(5244):\n",
    "    for j in range(3):\n",
    "        B[i][j] = -1 if B_raw[i][j] < 0 else 1\n",
    "\n",
    "#delete first label since there is no previous day data to predict\n",
    "B= np.delete(B, 0, 0)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#support vector machine using stochastic gradient descent, l1 regularization\n",
    "def gs_svm1( A, d, la_array ):\n",
    "    max_iter = 10**8\n",
    "    tol = 10**(-6)\n",
    "    tau = 1/np.linalg.norm(A,2)**2\n",
    "    n = A.shape[1]\n",
    "    m = A.shape[0]\n",
    "    w = np.zeros((n,1))\n",
    "    num_lam = len(la_array)\n",
    "    W = np.zeros((n, num_lam))\n",
    "    for i, each_lambda in enumerate(la_array):\n",
    "        for j in range(max_iter):\n",
    "            w_old = w\n",
    "            s = random.randint(0, m - 1)#random index for stochastic  \n",
    "            if (d[s]*np.dot(A[s], w)) < 1:\n",
    "                w = w + tau * ( (np.atleast_2d(A[s]).T * d[s]) - each_lambda * np.sign(w) / m) \n",
    "            else:\n",
    "                w = w - tau * each_lambda * np.sign(w) / m\n",
    "            W[:, i:i+1] = w\n",
    "            if np.linalg.norm(w - w_old) < tol:\n",
    "                break\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  10-fold CV \n",
    "\n",
    "# each row of setindices denotes the starting an ending index for one\n",
    "# partition of the data: 5 sets of 30 samples and 5 sets of 29 samples\n",
    "setindices = [[1,525],[526,1050],[1051,1575],[1576,2100],[2101,2625],[2626,3150],[3151,3675],[3676,4200],[4201,4725],[4726,5243]]\n",
    "\n",
    "# each row of holdoutindices denotes the partitions that are held out from\n",
    "# the training set\n",
    "holdoutindices = [[1,2],[2,3],[3,4],[4,5],[5,6],[7,8],[9,10],[10,1]]\n",
    "\n",
    "cases = len(holdoutindices)\n",
    "\n",
    "lam_vals = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "er_sq = np.zeros((cases,1))\n",
    "er_rate = np.zeros((cases,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# DJIA\n",
    "for j in range(cases):\n",
    "    # row indices of first validation set\n",
    "    v1_ind = np.arange(setindices[holdoutindices[j][0]-1][0]-1,setindices[holdoutindices[j][0]-1][1])\n",
    "    \n",
    "    # row indices of second validation set\n",
    "    v2_ind = np.arange(setindices[holdoutindices[j][1]-1][0]-1,setindices[holdoutindices[j][1]-1][1])\n",
    "    \n",
    "    # row indices of training set\n",
    "    trn_ind = list(set(range(5243))-set(v1_ind)-set(v2_ind))\n",
    "    \n",
    "    # define matrix of features and labels corresponding to first\n",
    "    # validation set\n",
    "    Av1 = A[v1_ind,:]\n",
    "    Bv1 = B[v1_ind,:]\n",
    "   \n",
    "    # define matrix of features and labels corresponding to second\n",
    "    # validation set\n",
    "    Av2 = A[v2_ind,:]\n",
    "    Bv2 = B[v2_ind,:]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to the \n",
    "    # training set\n",
    "    At = A[trn_ind,:]\n",
    "    Bt = B[trn_ind,:]\n",
    "\n",
    "    # Use training data to learn classifierA\n",
    "    W = gs_svm1(At,Bt[:,0].reshape((Bt.shape[0],1)),lam_vals)\n",
    "    # calculate error\n",
    "    er = np.zeros((26, 1))#error of the 26 lambda cases\n",
    "    miniEr = 1\n",
    "    miniErIndex = 0\n",
    "    for i in range(26):\n",
    "        Bp1 = np.sign(Av1@W[:,i])#predicted b\n",
    "        error_vec1 = [0 if Bv1[j][0]==Bp1[j] else 1 for j in range(len(Bv1))]\n",
    "        er[i] = sum(error_vec1) / len(Bv1)\n",
    "        if miniEr > er[i]:\n",
    "            miniEr = er[i]\n",
    "            \n",
    "    #get best lambda from above algorithm         \n",
    "#     print(miniErIndex)\n",
    "    lambda_b = lam_vals[miniErIndex]\n",
    "    #get best w from the lambda\n",
    "    w_b = W[:,miniErIndex]\n",
    "    #calculate predicted label for the second holdout evaluation data\n",
    "    Bp2 = np.sign(Av2@w_b)\n",
    "    #calculate the squared error and error rate\n",
    "    er_sq[j] = np.linalg.norm(Bp2 - Bv2[:,0], 2) / len(Bv2[:,0])\n",
    "    error_vec2 = [0 if Bv2[j][0]==Bp2[j] else 1 for j in range(len(Bv2[:,0]))]\n",
    "    er_rate[j] = sum(error_vec2) / len(Bv2[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier based on Dow Jones index:\n",
      "Square error for each case: \n",
      " [[0.06305884]\n",
      " [0.06047432]\n",
      " [0.05777429]\n",
      " [0.06224813]\n",
      " [0.0572697 ]\n",
      " [0.06011327]\n",
      " [0.05842759]\n",
      " [0.06142673]]\n",
      "Average square error: \n",
      " 0.060099108085930636\n",
      "Error rate for each case: \n",
      " [[0.52190476]\n",
      " [0.48      ]\n",
      " [0.43809524]\n",
      " [0.50857143]\n",
      " [0.43047619]\n",
      " [0.47428571]\n",
      " [0.44208494]\n",
      " [0.4952381 ]]\n",
      "Average error rate: \n",
      " 0.47383204633204634\n"
     ]
    }
   ],
   "source": [
    "print(\"The classifier based on Dow Jones index:\")\n",
    "print(\"Square error for each case: \\n\", er_sq)\n",
    "print(\"Average square error: \\n\", np.mean(er_sq))\n",
    "print(\"Error rate for each case: \\n\", er_rate)\n",
    "print(\"Average error rate: \\n\", np.mean(er_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SP500\n",
    "for j in range(cases):\n",
    "    # row indices of first validation set\n",
    "    v1_ind = np.arange(setindices[holdoutindices[j][0]-1][0]-1,setindices[holdoutindices[j][0]-1][1])\n",
    "    \n",
    "    # row indices of second validation set\n",
    "    v2_ind = np.arange(setindices[holdoutindices[j][1]-1][0]-1,setindices[holdoutindices[j][1]-1][1])\n",
    "    \n",
    "    # row indices of training set\n",
    "    trn_ind = list(set(range(5243))-set(v1_ind)-set(v2_ind))\n",
    "    \n",
    "    # define matrix of features and labels corresponding to first\n",
    "    # validation set\n",
    "    Av1 = A[v1_ind,:]\n",
    "    Bv1 = B[v1_ind,:]\n",
    "   \n",
    "    # define matrix of features and labels corresponding to second\n",
    "    # validation set\n",
    "    Av2 = A[v2_ind,:]\n",
    "    Bv2 = B[v2_ind,:]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to the \n",
    "    # training set\n",
    "    At = A[trn_ind,:]\n",
    "    Bt = B[trn_ind,:]\n",
    "\n",
    "    # Use training data to learn classifierA\n",
    "    W = gs_svm1(At,Bt[:,1].reshape((Bt.shape[0],1)),lam_vals)\n",
    "  \n",
    "    #calculate error\n",
    "    er = np.zeros((26, 1))#error of the 26 lambda cases\n",
    "    miniEr = 1\n",
    "    miniErIndex = 0\n",
    "    for i in range(26):\n",
    "        Bp1 = np.sign(Av1@W[:,i])#predicted b\n",
    "        error_vec1 = [0 if Bv1[j][1]==Bp1[j] else 1 for j in range(len(Bv1[:,1]))]\n",
    "        er[i] = sum(error_vec1) / len(Bv1[:,1])\n",
    "        if miniEr > er[i]:\n",
    "            miniEr = er[i]\n",
    "            miniErIndex = i\n",
    "            \n",
    "    #get best lambda from above algorithm         \n",
    "    lambda_b = lam_vals[miniErIndex]\n",
    "    #get best w from the lambda\n",
    "    w_b = W[:,miniErIndex]\n",
    "    #calculate predicted label for the second holdout evaluation data\n",
    "    Bp2 = np.sign(Av2@w_b)\n",
    "    #calculate the squared error and error rate\n",
    "    er_sq[j] = np.linalg.norm(Bp2 - Bv2[:,1], 2) / len(Bv2[:,1])\n",
    "    error_vec2 = [0 if Bv2[j][1]==Bp2[j] else 1 for j in range(len(Bv2[:,1]))]\n",
    "    er_rate[j] = sum(error_vec2) / len(Bv2[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier based on SP500 index:\n",
      "Square error for each case: \n",
      " [[0.06419924]\n",
      " [0.05852302]\n",
      " [0.05764856]\n",
      " [0.06107131]\n",
      " [0.05752255]\n",
      " [0.06011327]\n",
      " [0.05817189]\n",
      " [0.06178009]]\n",
      "Average square error: \n",
      " 0.05987874036523351\n",
      "Error rate for each case: \n",
      " [[0.54095238]\n",
      " [0.44952381]\n",
      " [0.43619048]\n",
      " [0.48952381]\n",
      " [0.43428571]\n",
      " [0.47428571]\n",
      " [0.43822394]\n",
      " [0.50095238]]\n",
      "Average error rate: \n",
      " 0.470492277992278\n"
     ]
    }
   ],
   "source": [
    "print(\"The classifier based on SP500 index:\")\n",
    "print(\"Square error for each case: \\n\", er_sq)\n",
    "print(\"Average square error: \\n\", np.mean(er_sq))\n",
    "print(\"Error rate for each case: \\n\", er_rate)\n",
    "print(\"Average error rate: \\n\", np.mean(er_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.15118229  0.1741951  -0.11715783  0.11772759]\n",
      "[ 0.13689789  0.12834641 -0.08757795  0.09276897]\n",
      "[ 0.1075475   0.18260347 -0.11269674  0.11467455]\n",
      "[ 0.09506978  0.20215531 -0.10616361  0.11292075]\n",
      "[ 0.13902526  0.08744171 -0.07169355  0.08261886]\n",
      "[ 0.14175003  0.08621996 -0.07020868  0.07307276]\n",
      "[ 0.13581868  0.18045474 -0.09304268  0.09747154]\n",
      "[ 0.12924061  0.18256701 -0.10478768  0.11092147]\n"
     ]
    }
   ],
   "source": [
    "# NASDAQ\n",
    "for j in range(cases):\n",
    "    # row indices of first validation set\n",
    "    v1_ind = np.arange(setindices[holdoutindices[j][0]-1][0]-1,setindices[holdoutindices[j][0]-1][1])\n",
    "    \n",
    "    # row indices of second validation set\n",
    "    v2_ind = np.arange(setindices[holdoutindices[j][1]-1][0]-1,setindices[holdoutindices[j][1]-1][1])\n",
    "    \n",
    "    # row indices of training set\n",
    "    trn_ind = list(set(range(5243))-set(v1_ind)-set(v2_ind))\n",
    "    \n",
    "    # define matrix of features and labels corresponding to first\n",
    "    # validation set\n",
    "    Av1 = A[v1_ind,:]\n",
    "    Bv1 = B[v1_ind,:]\n",
    "   \n",
    "    # define matrix of features and labels corresponding to second\n",
    "    # validation set\n",
    "    Av2 = A[v2_ind,:]\n",
    "    Bv2 = B[v2_ind,:]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to the \n",
    "    # training set\n",
    "    At = A[trn_ind,:]\n",
    "    Bt = B[trn_ind,:]\n",
    "\n",
    "    # Use training data to learn classifierA\n",
    "    W = gs_svm1(At,Bt[:,2].reshape((Bt.shape[0],1)),lam_vals)\n",
    "    #calculate error\n",
    "    er = np.zeros((26, 1))#error of the 26 lambda cases\n",
    "    \n",
    "    miniEr = 1\n",
    "    miniErIndex = 0\n",
    "    for i in range(26):\n",
    "        Bp1 = np.sign(Av1@W[:,i])#predicted b\n",
    "        error_vec1 = [0 if Bv1[j][2]==Bp1[j] else 1 for j in range(len(Bv1[:,2]))]\n",
    "        er[i] = sum(error_vec1) / len(Bv1[:,2])\n",
    "        if miniEr > er[i]:\n",
    "            miniEr = er[i]\n",
    "            miniErIndex = i\n",
    "            \n",
    "    #get best lambda from above algorithm         \n",
    "    lambda_b = lam_vals[miniErIndex]\n",
    "    #get best w from the lambda\n",
    "    w_b = W[:,miniErIndex]\n",
    "    print(w_b)\n",
    "    #calculate predicted label for the second holdout evaluation data\n",
    "    Bp2 = np.sign(Av2@w_b)\n",
    "    #calculate the squared error and error rate\n",
    "    er_sq[j] = np.linalg.norm(Bp2 - Bv2[:,2], 2) / len(Bv2[:,2])\n",
    "    error_vec2 = [0 if Bv2[j][2]==Bp2[j] else 1 for j in range(len(Bv2[:,2]))]\n",
    "    er_rate[j] = sum(error_vec2) / len(Bv2[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier based on Nasdaq index:\n",
      "Square error for each case: \n",
      " [[0.06305884]\n",
      " [0.06023386]\n",
      " [0.05739626]\n",
      " [0.06178009]\n",
      " [0.0563758 ]\n",
      " [0.05839889]\n",
      " [0.05829988]\n",
      " [0.05987137]]\n",
      "Average square error: \n",
      " 0.05942687522414974\n",
      "Error rate for each case: \n",
      " [[0.52190476]\n",
      " [0.47619048]\n",
      " [0.43238095]\n",
      " [0.50095238]\n",
      " [0.41714286]\n",
      " [0.44761905]\n",
      " [0.44015444]\n",
      " [0.47047619]]\n",
      "Average error rate: \n",
      " 0.4633526383526384\n"
     ]
    }
   ],
   "source": [
    "print(\"The classifier based on Nasdaq index:\")\n",
    "print(\"Square error for each case: \\n\", er_sq)\n",
    "print(\"Average square error: \\n\", np.mean(er_sq))\n",
    "print(\"Error rate for each case: \\n\", er_rate)\n",
    "print(\"Average error rate: \\n\", np.mean(er_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#support vector machine using stochastic gradient descent, l2 regularization\n",
    "def gs_svm2( A, d, la_array ):\n",
    "    max_iter = 10**8\n",
    "    tol = 10**(-3) / 5000\n",
    "    tau = 1/np.linalg.norm(A,2)**2\n",
    "    n = A.shape[1]\n",
    "    m = A.shape[0]\n",
    "    w = np.zeros((n,1))\n",
    "    num_lam = len(la_array)\n",
    "    W = np.zeros((n, num_lam))\n",
    "    for i, each_lambda in enumerate(la_array):\n",
    "        for j in range(max_iter):\n",
    "            w_old = w\n",
    "            s = random.randint(0, m - 1)#random index for stochastic  \n",
    "            if (d[s]*np.dot(A[s], w)) < 1:\n",
    "                w = w + tau * ( (np.atleast_2d(A[s]).T * d[s]) - each_lambda * w/ m) \n",
    "            else:\n",
    "                w = w - tau * each_lambda * w / m\n",
    "            W[:, i:i+1] = w\n",
    "            if np.linalg.norm(w - w_old) < tol:\n",
    "                break\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.11867052  0.15116458 -0.17568614  0.12859155]\n",
      "[ 0.0777986   0.1670625  -0.15568683  0.11496373]\n",
      "[ 0.04340869  0.18051815 -0.14543832  0.11086273]\n",
      "[ 0.08302872  0.20581011 -0.12675097  0.13349934]\n",
      "[ 0.05204252  0.22350223 -0.1227453   0.12612732]\n",
      "[ 0.13755499  0.1752365  -0.11998646  0.10605705]\n",
      "[ 0.09361674  0.2087016  -0.12123533  0.10080242]\n",
      "[ 0.15211795  0.1735704  -0.09791106  0.11143615]\n"
     ]
    }
   ],
   "source": [
    "#Dow Jones\n",
    "for j in range(cases):\n",
    "        # row indices of first validation set\n",
    "    v1_ind = np.arange(setindices[holdoutindices[j][0]-1][0]-1,setindices[holdoutindices[j][0]-1][1])\n",
    "    \n",
    "    # row indices of second validation set\n",
    "    v2_ind = np.arange(setindices[holdoutindices[j][1]-1][0]-1,setindices[holdoutindices[j][1]-1][1])\n",
    "    \n",
    "    # row indices of training set\n",
    "    trn_ind = list(set(range(5243))-set(v1_ind)-set(v2_ind))\n",
    "    \n",
    "    # define matrix of features and labels corresponding to first\n",
    "    # validation set\n",
    "    Av1 = A[v1_ind,:]\n",
    "    bv1 = B[v1_ind,0]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to second\n",
    "    # validation set\n",
    "    Av2 = A[v2_ind,:]\n",
    "    bv2 = B[v2_ind,0]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to the \n",
    "    # training set\n",
    "    At = A[trn_ind,:]\n",
    "    bt = B[trn_ind,0]\n",
    "    \n",
    "    #train classifiers\n",
    "    W = gs_svm2(At,Bt[:,0].reshape((Bt.shape[0],1)),lam_vals)\n",
    "    \n",
    "    miniEr = 1\n",
    "    miniErIndex = 0\n",
    "    for i in range(26):\n",
    "#         Wr[:,i:i+1] = np.linalg.inv(At.T@At + lam_vals[i]*np.identity(At.shape[1]))@At.T@(bt.reshape(bt.shape[0],1))\n",
    "        bp1 = np.sign(Av1@W[:,i])#predicted b\n",
    "        error_vec1 = [0 if bv1[j]==bp1[j] else 1 for j in range(len(bv1))]\n",
    "        er[i] = sum(error_vec1) / len(bv1)\n",
    "        if miniEr > er[i]:\n",
    "            miniEr = er[i]\n",
    "            miniErIndex = i\n",
    "            \n",
    "    #get best lambda from above algorithm         \n",
    "    lambda_b = lam_vals[i]\n",
    "    #get best w from the lambda\n",
    "    w_b = W[:,i]\n",
    "    print(w_b)\n",
    "    #calculate predicted label for the second holdout evaluation data\n",
    "    bp2 = np.sign(Av2@w_b)\n",
    "    #calculate the squared error and error rate\n",
    "    er_sq[j] = np.linalg.norm(bp2 - bv2, 2) / len(bv2)\n",
    "    error_vec2 = [0 if bv2[j]==bp2[j] else 1 for j in range(len(bv2))]\n",
    "    er_rate[j] = sum(error_vec2) / len(bv2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier based on Dow Jones index:\n",
      "Square error for each case: \n",
      " [[0.06305884]\n",
      " [0.06047432]\n",
      " [0.05777429]\n",
      " [0.06224813]\n",
      " [0.0572697 ]\n",
      " [0.06011327]\n",
      " [0.05842759]\n",
      " [0.06142673]]\n",
      "Average square error: \n",
      " 0.060099108085930636\n",
      "Error rate for each case: \n",
      " [[0.52190476]\n",
      " [0.48      ]\n",
      " [0.43809524]\n",
      " [0.50857143]\n",
      " [0.43047619]\n",
      " [0.47428571]\n",
      " [0.44208494]\n",
      " [0.4952381 ]]\n",
      "Average error rate: \n",
      " 0.47383204633204634\n"
     ]
    }
   ],
   "source": [
    "print(\"The classifier based on Dow Jones index:\")\n",
    "print(\"Square error for each case: \\n\", er_sq)\n",
    "print(\"Average square error: \\n\", np.mean(er_sq))\n",
    "print(\"Error rate for each case: \\n\", er_rate)\n",
    "print(\"Average error rate: \\n\", np.mean(er_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SP500\n",
    "for j in range(cases):\n",
    "    # row indices of first validation set\n",
    "    v1_ind = np.arange(setindices[holdoutindices[j][0]-1][0]-1,setindices[holdoutindices[j][0]-1][1])\n",
    "    \n",
    "    # row indices of second validation set\n",
    "    v2_ind = np.arange(setindices[holdoutindices[j][1]-1][0]-1,setindices[holdoutindices[j][1]-1][1])\n",
    "    \n",
    "    # row indices of training set\n",
    "    trn_ind = list(set(range(5243))-set(v1_ind)-set(v2_ind))\n",
    "    \n",
    "    # define matrix of features and labels corresponding to first\n",
    "    # validation set\n",
    "    Av1 = A[v1_ind,:]\n",
    "    bv1 = B[v1_ind,1]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to second\n",
    "    # validation set\n",
    "    Av2 = A[v2_ind,:]\n",
    "    bv2 = B[v2_ind,1]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to the \n",
    "    # training set\n",
    "    At = A[trn_ind,:]\n",
    "    bt = B[trn_ind,1]\n",
    "    \n",
    "    #train classifiers\n",
    "    W = gs_svm2(At,Bt[:,1].reshape((Bt.shape[0],1)),lam_vals)\n",
    "    \n",
    "    miniEr = 1\n",
    "    miniErIndex = 0\n",
    "    for i in range(26):\n",
    "        bp1 = np.sign(Av1@W[:,i])#predicted b\n",
    "        error_vec1 = [0 if bv1[j]==bp1[j] else 1 for j in range(len(bv1))]\n",
    "        er[i] = sum(error_vec1) / len(bv1)\n",
    "        if miniEr > er[i]:\n",
    "            miniEr = er[i]\n",
    "            miniErIndex = i\n",
    "            \n",
    "    #get best lambda from above algorithm         \n",
    "    lambda_b = lam_vals[i]\n",
    "    #get best w from the lambda\n",
    "    w_b = W[:,i]\n",
    "    #calculate predicted label for the second holdout evaluation data\n",
    "    bp2 = np.sign(Av2@w_b)\n",
    "    #calculate the squared error and error rate\n",
    "    er_sq[j] = np.linalg.norm(bp2 - bv2, 2) / len(bv2)\n",
    "    error_vec2 = [0 if bv2[j]==bp2[j] else 1 for j in range(len(bv2))]\n",
    "    er_rate[j] = sum(error_vec2) / len(bv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier based on SP500 index:\n",
      "Square error for each case: \n",
      " [[0.06419924]\n",
      " [0.05852302]\n",
      " [0.05764856]\n",
      " [0.06107131]\n",
      " [0.05752255]\n",
      " [0.06011327]\n",
      " [0.05817189]\n",
      " [0.06178009]]\n",
      "Average square error: \n",
      " 0.05987874036523351\n",
      "Error rate for each case: \n",
      " [[0.54095238]\n",
      " [0.44952381]\n",
      " [0.43619048]\n",
      " [0.48952381]\n",
      " [0.43428571]\n",
      " [0.47428571]\n",
      " [0.43822394]\n",
      " [0.50095238]]\n",
      "Average error rate: \n",
      " 0.470492277992278\n"
     ]
    }
   ],
   "source": [
    "print(\"The classifier based on SP500 index:\")\n",
    "print(\"Square error for each case: \\n\", er_sq)\n",
    "print(\"Average square error: \\n\", np.mean(er_sq))\n",
    "print(\"Error rate for each case: \\n\", er_rate)\n",
    "print(\"Average error rate: \\n\", np.mean(er_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NASDAQ\n",
    "for j in range(cases):\n",
    "    # row indices of first validation set\n",
    "    v1_ind = np.arange(setindices[holdoutindices[j][0]-1][0]-1,setindices[holdoutindices[j][0]-1][1])\n",
    "    \n",
    "    # row indices of second validation set\n",
    "    v2_ind = np.arange(setindices[holdoutindices[j][1]-1][0]-1,setindices[holdoutindices[j][1]-1][1])\n",
    "    \n",
    "    # row indices of training set\n",
    "    trn_ind = list(set(range(5243))-set(v1_ind)-set(v2_ind))\n",
    "    \n",
    "    # define matrix of features and labels corresponding to first\n",
    "    # validation set\n",
    "    Av1 = A[v1_ind,:]\n",
    "    bv1 = B[v1_ind,2]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to second\n",
    "    # validation set\n",
    "    Av2 = A[v2_ind,:]\n",
    "    bv2 = B[v2_ind,2]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to the \n",
    "    # training set\n",
    "    At = A[trn_ind,:]\n",
    "    bt = B[trn_ind,2]\n",
    "    \n",
    "    #train classifiers\n",
    "    W = gs_svm2(At,Bt[:,2].reshape((Bt.shape[0],1)),lam_vals)\n",
    "    \n",
    "    for i in range(26):\n",
    "        bp1 = np.sign(Av1@W[:,i])#predicted b\n",
    "        error_vec1 = [0 if bv1[j]==bp1[j] else 1 for j in range(len(bv1))]\n",
    "        er[i] = sum(error_vec1) / len(bv1)\n",
    "        if miniEr > er[i]:\n",
    "            miniEr = er[i]\n",
    "            miniErIndex = i\n",
    "            \n",
    "    #get best lambda from above algorithm         \n",
    "    lambda_b = lam_vals[i]\n",
    "    #get best w from the lambda\n",
    "    w_b = W[:,i]\n",
    "    #calculate predicted label for the second holdout evaluation data\n",
    "    bp2 = np.sign(Av2@w_b)\n",
    "    #calculate the squared error and error rate\n",
    "    er_sq[j] = np.linalg.norm(bp2 - bv2, 2) / len(bv2)\n",
    "    error_vec2 = [0 if bv2[j]==bp2[j] else 1 for j in range(len(bv2))]\n",
    "    er_rate[j] = sum(error_vec2) / len(bv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier based on NASDAQ index:\n",
      "Square error for each case: \n",
      " [[0.06305884]\n",
      " [0.06023386]\n",
      " [0.05739626]\n",
      " [0.06178009]\n",
      " [0.0563758 ]\n",
      " [0.05839889]\n",
      " [0.05829988]\n",
      " [0.05987137]]\n",
      "Average square error: \n",
      " 0.05942687522414974\n",
      "Error rate for each case: \n",
      " [[0.52190476]\n",
      " [0.47619048]\n",
      " [0.43238095]\n",
      " [0.50095238]\n",
      " [0.41714286]\n",
      " [0.44761905]\n",
      " [0.44015444]\n",
      " [0.47047619]]\n",
      "Average error rate: \n",
      " 0.4633526383526384\n"
     ]
    }
   ],
   "source": [
    "print(\"The classifier based on NASDAQ index:\")\n",
    "print(\"Square error for each case: \\n\", er_sq)\n",
    "print(\"Average square error: \\n\", np.mean(er_sq))\n",
    "print(\"Error rate for each case: \\n\", er_rate)\n",
    "print(\"Average error rate: \\n\", np.mean(er_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
