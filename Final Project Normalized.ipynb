{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5243,)\n",
      "(5243,)\n"
     ]
    }
   ],
   "source": [
    "#setup data\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#define risk free rate(rfr) as the three month treasure yield (DGS3MO)\n",
    "rfr = np.array((5244,1))\n",
    "#define term spread as 10 year treasure interest(DGS10) minus 1 year treasure interest(DGS1)\n",
    "ts = np.array((5244,1))\n",
    "#define default spread as the yield gap between AAA(DAAA) and BBB(DBAA) grade bonds\n",
    "ds = np.array((5244,1))\n",
    "ones = np.ones((5243,1))[:,0]\n",
    "\n",
    "data1 = pd.read_csv('spread.csv')\n",
    "data2 = pd.read_csv('StockMarket.csv')\n",
    "data = pd.merge(data1, data2, on='Date')\n",
    "rfr = data['DGS3MO']\n",
    "ds = data['DGS10'] - data['DGS1']\n",
    "ts = data['DBAA'] - data['DAAA']\n",
    "# print(rfr.shape)\n",
    "# print(ds.shape)\n",
    "# print(ts.shape)\n",
    "# print(ones.shape)\n",
    "# A = np.stack((rfr, ds, ts, ones), axis = 1)\n",
    "\n",
    "rfr2=np.zeros((5243,))\n",
    "ds2=np.zeros((5243,))\n",
    "ts2=np.zeros((5243,))\n",
    "for i in range(5243):\n",
    "    rfr2[i] = rfr[i+1]-rfr[i]\n",
    "    ds2[i] = ds[i+1]-ds[i]\n",
    "    ts2[i] = ts[i+1]-ts[i]\n",
    "#delete the last data since there is no label for the next day\n",
    "# print(data)\n",
    "print(rfr[1:].shape)\n",
    "print(rfr2.shape)\n",
    "A = np.stack((rfr[1:], ds[1:], ts[1:], rfr2, ds2, ts2, ones), axis = 1)\n",
    "A = preprocessing.normalize(A)\n",
    "# print(A)\n",
    "\n",
    "#the yield of three major index: Dow Jones, SP 500 and Nasdaq\n",
    "B_raw = np.stack((data['DJIA'], data['SP500'], data['NASDAQ']), axis = 1)\n",
    "#Labeled as -1 if the market loss the next day, +1 otherwise \n",
    "B = np.zeros((5244, 3))\n",
    "for i in range(5244):\n",
    "    for j in range(3):\n",
    "        B[i][j] = -1 if B_raw[i][j] < 0 else 1\n",
    "\n",
    "#delete first label since there is no previous day data to predict\n",
    "B= np.delete(B, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LASSO, this code is copied from previous assignment\n",
    "def ista_solve_hot( A, d, la_array ):\n",
    "    # ista_solve_hot: Iterative soft-thresholding for multiple values of\n",
    "    # lambda with hot start for each case - the converged value for the previous\n",
    "    # value of lambda is used as an initial condition for the current lambda.\n",
    "    # this function solves the minimization problem\n",
    "    # Minimize |Ax-d|_2^2 + lambda*|x|_1 (Lasso regression)\n",
    "    # using iterative soft-thresholding.\n",
    "    max_iter = 10**4\n",
    "    tol = 10**(-3)\n",
    "    tau = 1/np.linalg.norm(A,2)**2\n",
    "    n = A.shape[1]\n",
    "    w = np.zeros((n,1))\n",
    "    num_lam = len(la_array)\n",
    "    X = np.zeros((n, num_lam))\n",
    "    for i, each_lambda in enumerate(la_array):\n",
    "        for j in range(max_iter):\n",
    "            z = w - tau*(A.T@(A@w-d))\n",
    "            w_old = w\n",
    "            w = np.sign(z) * np.clip(np.abs(z)-tau*each_lambda/2, 0, np.inf)\n",
    "            X[:, i:i+1] = w\n",
    "            if np.linalg.norm(w - w_old) < tol:\n",
    "                break\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  10-fold CV \n",
    "\n",
    "# each row of setindices denotes the starting an ending index for one\n",
    "# partition of the data: 5 sets of 30 samples and 5 sets of 29 samples\n",
    "setindices = [[1,525],[526,1050],[1051,1575],[1576,2100],[2101,2625],[2626,3150],[3151,3675],[3676,4200],[4201,4725],[4726,5243]]\n",
    "\n",
    "# each row of holdoutindices denotes the partitions that are held out from\n",
    "# the training set\n",
    "holdoutindices = [[1,2],[2,3],[3,4],[4,5],[5,6],[7,8],[9,10],[10,1]]\n",
    "\n",
    "cases = len(holdoutindices)\n",
    "\n",
    "lam_vals = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "er_sq = np.zeros((cases,1))\n",
    "er_rate = np.zeros((cases,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08036904  0.05986824 -0.0477641   2.43947407  9.90650101 -0.\n",
      "  0.08890593]\n",
      "[ 0.04779435  0.05841017 -0.14733096  4.17609316 10.91987034 -0.\n",
      "  0.22801151]\n",
      "[-1.41639770e-02  1.27278087e-04 -9.42230595e-02  2.93776971e+00\n",
      "  9.45296114e+00 -0.00000000e+00  2.69581207e-01]\n",
      "[-9.02092539e-03  1.46648727e-02  0.00000000e+00  0.00000000e+00\n",
      "  1.13108383e+01 -0.00000000e+00  1.64663665e-01]\n",
      "[-0.01623114 -0.08573469 -0.21891734  1.67038219 10.88614437  0.164961\n",
      "  0.53274907]\n",
      "[-0.         -0.01757203 -0.07230785  4.33011683  7.32350477 -0.\n",
      "  0.2856456 ]\n",
      "[ 0.02284861  0.06673981 -0.01632593  1.27013733  6.51539141 -0.\n",
      "  0.        ]\n",
      "[ 0.0267635   0.03359929 -0.0223031   1.00986665  7.41534624 -0.\n",
      "  0.09534923]\n"
     ]
    }
   ],
   "source": [
    "# DJIA\n",
    "for j in range(cases):\n",
    "    # row indices of first validation set\n",
    "    v1_ind = np.arange(setindices[holdoutindices[j][0]-1][0]-1,setindices[holdoutindices[j][0]-1][1])\n",
    "    \n",
    "    # row indices of second validation set\n",
    "    v2_ind = np.arange(setindices[holdoutindices[j][1]-1][0]-1,setindices[holdoutindices[j][1]-1][1])\n",
    "    \n",
    "    # row indices of training set\n",
    "    trn_ind = list(set(range(5243))-set(v1_ind)-set(v2_ind))\n",
    "    \n",
    "    # define matrix of features and labels corresponding to first\n",
    "    # validation set\n",
    "    Av1 = A[v1_ind,:]\n",
    "    Bv1 = B[v1_ind,:]\n",
    "   \n",
    "    # define matrix of features and labels corresponding to second\n",
    "    # validation set\n",
    "    Av2 = A[v2_ind,:]\n",
    "    Bv2 = B[v2_ind,:]\n",
    "    \n",
    "    \n",
    "    # define matrix of features and labels corresponding to the \n",
    "    # training set\n",
    "    At = A[trn_ind,:]\n",
    "    Bt = B[trn_ind,:]\n",
    "    \n",
    "    # Use training data to learn classifierA\n",
    "    W = ista_solve_hot(At,Bt[:,0].reshape((Bt.shape[0],1)),lam_vals)\n",
    "  \n",
    "    #calculate error in the 26 w coresponding to each lambda\n",
    "    er = np.zeros((26, 1))#error of the 26 lambda cases\n",
    "    miniEr = 1\n",
    "    miniErIndex = 0\n",
    "    for i in range(26):\n",
    "        Bp1 = np.sign(Av1@W[:,i])#predicted b\n",
    "        error_vec1 = [0 if Bv1[j][0]==Bp1[j] else 1 for j in range(len(Bv1))]\n",
    "        er[i] = sum(error_vec1) / len(Bv1)\n",
    "        #select the best lambda with the least error rate\n",
    "        if miniEr > er[i]:\n",
    "            miniEr = er[i]\n",
    "            miniErIndex = i\n",
    "            \n",
    "    #get best lambda from above algorithm\n",
    "    lambda_b = lam_vals[miniErIndex]\n",
    "    #get best w from the lambda\n",
    "    w_b = W[:,miniErIndex]\n",
    "    print(w_b)\n",
    "    #calculate predicted label for the second holdout evaluation data\n",
    "    Bp2 = np.sign(Av2@w_b)\n",
    "    #calculate the squared error and error rate\n",
    "    er_sq[j] = np.linalg.norm(Bp2 - Bv2[:,0], 2) / len(Bv2[:,0])\n",
    "    error_vec2 = [0 if Bv2[j][0]==Bp2[j] else 1 for j in range(len(Bv2[:,0]))]\n",
    "    er_rate[j] = sum(error_vec2) / len(Bv2[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier based on Dow Jones index:\n",
      "Square error for each case: \n",
      " [[0.05987137]\n",
      " [0.05852302]\n",
      " [0.05901689]\n",
      " [0.06023386]\n",
      " [0.05111013]\n",
      " [0.05237229]\n",
      " [0.05446616]\n",
      " [0.06236459]]\n",
      "Average square error: \n",
      " 0.05724478803213348\n",
      "Error rate for each case: \n",
      " [[0.47047619]\n",
      " [0.44952381]\n",
      " [0.45714286]\n",
      " [0.47619048]\n",
      " [0.34285714]\n",
      " [0.36      ]\n",
      " [0.38416988]\n",
      " [0.51047619]]\n",
      "Average error rate: \n",
      " 0.4313545688545689\n"
     ]
    }
   ],
   "source": [
    "print(\"The classifier based on Dow Jones index:\")\n",
    "print(\"Square error for each case: \\n\", er_sq)\n",
    "print(\"Average square error: \\n\", np.mean(er_sq))\n",
    "print(\"Error rate for each case: \\n\", er_rate)\n",
    "print(\"Average error rate: \\n\", np.mean(er_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.10295775  0.09408032 -0.          0.          6.19963711 -0.\n",
      "  0.        ]\n",
      "[ 0.03541233  0.05092421 -0.10000606  4.36730054 10.67503204 -0.61221141\n",
      "  0.23030008]\n",
      "[-0.03202021 -0.         -0.          2.19386896  8.39756178 -0.\n",
      "  0.19916111]\n",
      "[-0.01227806  0.03054814  0.          0.          8.51924428 -0.\n",
      "  0.15408294]\n",
      "[-0.         -0.03840914 -0.          0.09423001  9.46025245 -0.\n",
      "  0.2562892 ]\n",
      "[-7.46634294e-05 -1.48330685e-02 -9.09843177e-03  3.77408274e+00\n",
      "  6.23414398e+00 -0.00000000e+00  2.34450450e-01]\n",
      "[ 0.          0.04164808 -0.          3.84573874  8.65084031 -0.\n",
      "  0.10912329]\n",
      "[ 0.01607843  0.02770232 -0.02679579  4.15103539  9.53928131 -0.\n",
      "  0.15943008]\n"
     ]
    }
   ],
   "source": [
    "# SP500\n",
    "for j in range(cases):\n",
    "    # row indices of first validation set\n",
    "    v1_ind = np.arange(setindices[holdoutindices[j][0]-1][0]-1,setindices[holdoutindices[j][0]-1][1])\n",
    "    \n",
    "    # row indices of second validation set\n",
    "    v2_ind = np.arange(setindices[holdoutindices[j][1]-1][0]-1,setindices[holdoutindices[j][1]-1][1])\n",
    "    \n",
    "    # row indices of training set\n",
    "    trn_ind = list(set(range(5243))-set(v1_ind)-set(v2_ind))\n",
    "    \n",
    "    # define matrix of features and labels corresponding to first\n",
    "    # validation set\n",
    "    Av1 = A[v1_ind,:]\n",
    "    Bv1 = B[v1_ind,:]\n",
    "   \n",
    "    # define matrix of features and labels corresponding to second\n",
    "    # validation set\n",
    "    Av2 = A[v2_ind,:]\n",
    "    Bv2 = B[v2_ind,:]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to the \n",
    "    # training set\n",
    "    At = A[trn_ind,:]\n",
    "    Bt = B[trn_ind,:]\n",
    "\n",
    "    # Use training data to learn classifierA\n",
    "    W = ista_solve_hot(At,Bt[:,1].reshape((Bt.shape[0],1)),lam_vals)\n",
    "  \n",
    "    #calculate error in the 26 w coresponding to each lambda\n",
    "    er = np.zeros((26, 1))#error of the 26 lambda cases\n",
    "    miniEr = 1\n",
    "    miniErIndex = 0\n",
    "    for i in range(26):\n",
    "        Bp1 = np.sign(Av1@W[:,i])#predicted b\n",
    "        error_vec1 = [0 if Bv1[j][0]==Bp1[j] else 1 for j in range(len(Bv1))]\n",
    "        er[i] = sum(error_vec1) / len(Bv1)\n",
    "        #select the best lambda with the least error rate\n",
    "        if miniEr > er[i]:\n",
    "            miniEr = er[i]\n",
    "            miniErIndex = i\n",
    "            \n",
    "    #get best lambda from above algorithm         \n",
    "    lambda_b = lam_vals[miniErIndex]\n",
    "    #get best w from the lambda\n",
    "    w_b = W[:,miniErIndex]\n",
    "    print(w_b)\n",
    "    #calculate predicted label for the second holdout evaluation data\n",
    "    Bp2 = np.sign(Av2@w_b)\n",
    "    #calculate the squared error and error rate\n",
    "    er_sq[j] = np.linalg.norm(Bp2 - Bv2[:,1], 2) / len(Bv2[:,1])\n",
    "    error_vec2 = [0 if Bv2[j][1]==Bp2[j] else 1 for j in range(len(Bv2[:,1]))]\n",
    "    er_rate[j] = sum(error_vec2) / len(Bv2[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier based on SP500 index:\n",
      "Square error for each case: \n",
      " [[0.06340311]\n",
      " [0.05789975]\n",
      " [0.06095238]\n",
      " [0.06083322]\n",
      " [0.05039526]\n",
      " [0.05306053]\n",
      " [0.05487518]\n",
      " [0.06259686]]\n",
      "Average square error: \n",
      " 0.058002036013386035\n",
      "Error rate for each case: \n",
      " [[0.52761905]\n",
      " [0.44      ]\n",
      " [0.48761905]\n",
      " [0.48571429]\n",
      " [0.33333333]\n",
      " [0.36952381]\n",
      " [0.38996139]\n",
      " [0.51428571]]\n",
      "Average error rate: \n",
      " 0.4435070785070785\n"
     ]
    }
   ],
   "source": [
    "print(\"The classifier based on SP500 index:\")\n",
    "print(\"Square error for each case: \\n\", er_sq)\n",
    "print(\"Average square error: \\n\", np.mean(er_sq))\n",
    "print(\"Error rate for each case: \\n\", er_rate)\n",
    "print(\"Average error rate: \\n\", np.mean(er_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.06648327  0.06850848 -0.          0.          7.10061309 -0.\n",
      "  0.09739811]\n",
      "[ 0.06710824  0.11767862 -0.22551848  3.52265516  9.48416035 -0.62017677\n",
      "  0.28508892]\n",
      "[-0.01037975  0.03237035 -0.09397654  2.30055291  8.15610979 -0.\n",
      "  0.28681094]\n",
      "[-0.          0.0321353  -0.          0.          8.75168376 -0.\n",
      "  0.19422174]\n",
      "[-0.01706789 -0.0751998  -0.33516526  1.61865668  8.7671602   0.04167634\n",
      "  0.69485628]\n",
      "[-0.02324134 -0.04252149 -0.14427361  3.16119691  6.21317359 -0.20836392\n",
      "  0.49543587]\n",
      "[ 2.01229616e-02  5.99876972e-02 -7.98089942e-03  2.84665801e+00\n",
      "  8.02213126e+00 -0.00000000e+00  8.72630494e-02]\n",
      "[-1.59834760e-02 -2.41513508e-03 -2.19637563e-01  3.56259953e+00\n",
      "  8.93475105e+00 -8.51474685e-01  4.86517044e-01]\n"
     ]
    }
   ],
   "source": [
    "# NASDAQ\n",
    "for j in range(cases):\n",
    "    # row indices of first validation set\n",
    "    v1_ind = np.arange(setindices[holdoutindices[j][0]-1][0]-1,setindices[holdoutindices[j][0]-1][1])\n",
    "    \n",
    "    # row indices of second validation set\n",
    "    v2_ind = np.arange(setindices[holdoutindices[j][1]-1][0]-1,setindices[holdoutindices[j][1]-1][1])\n",
    "    \n",
    "    # row indices of training set\n",
    "    trn_ind = list(set(range(5243))-set(v1_ind)-set(v2_ind))\n",
    "    \n",
    "    # define matrix of features and labels corresponding to first\n",
    "    # validation set\n",
    "    Av1 = A[v1_ind,:]\n",
    "    Bv1 = B[v1_ind,:]\n",
    "   \n",
    "    # define matrix of features and labels corresponding to second\n",
    "    # validation set\n",
    "    Av2 = A[v2_ind,:]\n",
    "    Bv2 = B[v2_ind,:]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to the \n",
    "    # training set\n",
    "    At = A[trn_ind,:]\n",
    "    Bt = B[trn_ind,:]\n",
    "\n",
    "    # Use training data to learn classifierA\n",
    "    W = ista_solve_hot(At,Bt[:,2].reshape((Bt.shape[0],1)),lam_vals)\n",
    "    #calculate error in the 26 w coresponding to each lambda\n",
    "    er = np.zeros((26, 1))#error of the 26 lambda cases\n",
    "    miniEr = 1\n",
    "    miniErIndex = 0\n",
    "    for i in range(26):\n",
    "        Bp1 = np.sign(Av1@W[:,i])#predicted b\n",
    "        error_vec1 = [0 if Bv1[j][0]==Bp1[j] else 1 for j in range(len(Bv1))]\n",
    "        er[i] = sum(error_vec1) / len(Bv1)\n",
    "        #select the best lambda with the least error rate\n",
    "        if miniEr > er[i]:\n",
    "            miniEr = er[i]\n",
    "            miniErIndex = i\n",
    "            \n",
    "    #get best lambda from above algorithm         \n",
    "    lambda_b = lam_vals[miniErIndex]\n",
    "    #get best w from the lambda\n",
    "    w_b = W[:,miniErIndex]\n",
    "    print(w_b)\n",
    "    #calculate predicted label for the second holdout evaluation data\n",
    "    Bp2 = np.sign(Av2@w_b)\n",
    "    #calculate the squared error and error rate\n",
    "    er_sq[j] = np.linalg.norm(Bp2 - Bv2[:,2], 2) / len(Bv2[:,2])\n",
    "    error_vec2 = [0 if Bv2[j][2]==Bp2[j] else 1 for j in range(len(Bv2[:,2]))]\n",
    "    er_rate[j] = sum(error_vec2) / len(Bv2[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier based on Nasdaq index:\n",
      "Square error for each case: \n",
      " [[0.06224813]\n",
      " [0.05852302]\n",
      " [0.05789975]\n",
      " [0.06071382]\n",
      " [0.05153428]\n",
      " [0.05400932]\n",
      " [0.05555017]\n",
      " [0.06047432]]\n",
      "Average square error: \n",
      " 0.057619100911444746\n",
      "Error rate for each case: \n",
      " [[0.50857143]\n",
      " [0.44952381]\n",
      " [0.44      ]\n",
      " [0.48380952]\n",
      " [0.34857143]\n",
      " [0.38285714]\n",
      " [0.3996139 ]\n",
      " [0.48      ]]\n",
      "Average error rate: \n",
      " 0.43661840411840414\n"
     ]
    }
   ],
   "source": [
    "print(\"The classifier based on Nasdaq index:\")\n",
    "print(\"Square error for each case: \\n\", er_sq)\n",
    "print(\"Average square error: \\n\", np.mean(er_sq))\n",
    "print(\"Error rate for each case: \\n\", er_rate)\n",
    "print(\"Average error rate: \\n\", np.mean(er_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08853657  0.0787489  -0.12009569  0.1689477   0.69758885 -0.02112105\n",
      "  0.11993684]\n",
      "[ 0.07184086  0.09848296 -0.15687952  0.18176761  0.64689437 -0.02299645\n",
      "  0.1485909 ]\n",
      "[-0.00572101  0.0330991  -0.15244322  0.22299614  0.68765842 -0.02166047\n",
      "  0.26560843]\n",
      "[-0.01478094  0.02602155 -0.05211053  0.05040909  0.74131176 -0.00157158\n",
      "  0.19392365]\n",
      "[ 0.0111633  -0.04268383 -0.04950572  0.0541161   0.58895615  0.01358938\n",
      "  0.25997881]\n",
      "[ 0.00790516 -0.01051843 -0.06496415  0.22236071  0.39506894 -0.00652432\n",
      "  0.24555262]\n",
      "[ 0.02724909  0.08047955 -0.13184656  0.22319353  0.55007252 -0.04335162\n",
      "  0.09671964]\n",
      "[ 0.03746187  0.05860072 -0.13584426  0.21548329  0.66055527 -0.03726577\n",
      "  0.16014676]\n"
     ]
    }
   ],
   "source": [
    "#Ridge Regression\n",
    "#Dow Jones\n",
    "for j in range(cases):\n",
    "        # row indices of first validation set\n",
    "    v1_ind = np.arange(setindices[holdoutindices[j][0]-1][0]-1,setindices[holdoutindices[j][0]-1][1])\n",
    "    \n",
    "    # row indices of second validation set\n",
    "    v2_ind = np.arange(setindices[holdoutindices[j][1]-1][0]-1,setindices[holdoutindices[j][1]-1][1])\n",
    "    \n",
    "    # row indices of training set\n",
    "    trn_ind = list(set(range(5243))-set(v1_ind)-set(v2_ind))\n",
    "    \n",
    "    # define matrix of features and labels corresponding to first\n",
    "    # validation set\n",
    "    Av1 = A[v1_ind,:]\n",
    "    bv1 = B[v1_ind,0]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to second\n",
    "    # validation set\n",
    "    Av2 = A[v2_ind,:]\n",
    "    bv2 = B[v2_ind,0]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to the \n",
    "    # training set\n",
    "    At = A[trn_ind,:]\n",
    "    bt = B[trn_ind,0]\n",
    "    \n",
    "\n",
    "    Wr = np.zeros((At.shape[1], 26))\n",
    "    \n",
    "    miniEr = 1\n",
    "    miniErIndex = 0\n",
    "    for i in range(26):\n",
    "        #train the data with one of the each lambda and add into Wr\n",
    "        Wr[:,i:i+1] = np.linalg.inv(At.T@At + lam_vals[i]*np.identity(At.shape[1]))@At.T@(bt.reshape(bt.shape[0],1))\n",
    "        bp1 = np.sign(Av1@Wr[:,i])#predicted b\n",
    "        error_vec1 = [0 if bv1[j]==bp1[j] else 1 for j in range(len(bv1))]\n",
    "        er[i] = sum(error_vec1) / len(bv1)\n",
    "        if miniEr > er[i]:\n",
    "            miniEr = er[i]\n",
    "            miniErIndex = i\n",
    "            \n",
    "    #get best lambda from above algorithm         \n",
    "    lambda_b = lam_vals[i]\n",
    "    #get best w from the lambda\n",
    "    w_b = Wr[:,i]\n",
    "    print(w_b)\n",
    "    #calculate predicted label for the second holdout evaluation data\n",
    "    bp2 = np.sign(Av2@w_b)\n",
    "    #calculate the squared error and error rate\n",
    "    er_sq[j] = np.linalg.norm(bp2 - bv2, 2) / len(bv2)\n",
    "    error_vec2 = [0 if bv2[j]==bp2[j] else 1 for j in range(len(bv2))]\n",
    "    er_rate[j] = sum(error_vec2) / len(bv2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier based on Dow Jones index:\n",
      "Square error for each case: \n",
      " [[0.06305884]\n",
      " [0.06047432]\n",
      " [0.05777429]\n",
      " [0.06213145]\n",
      " [0.05752255]\n",
      " [0.06011327]\n",
      " [0.05739795]\n",
      " [0.06142673]]\n",
      "Average square error: \n",
      " 0.05998742395974471\n",
      "Error rate for each case: \n",
      " [[0.52190476]\n",
      " [0.48      ]\n",
      " [0.43809524]\n",
      " [0.50666667]\n",
      " [0.43428571]\n",
      " [0.47428571]\n",
      " [0.42664093]\n",
      " [0.4952381 ]]\n",
      "Average error rate: \n",
      " 0.4721396396396397\n"
     ]
    }
   ],
   "source": [
    "print(\"The classifier based on Dow Jones index:\")\n",
    "print(\"Square error for each case: \\n\", er_sq)\n",
    "print(\"Average square error: \\n\", np.mean(er_sq))\n",
    "print(\"Error rate for each case: \\n\", er_rate)\n",
    "print(\"Average error rate: \\n\", np.mean(er_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.10658396  0.10276352 -0.06551069  0.17096253  0.66887173 -0.01855277\n",
      "  0.05378851]\n",
      "[ 0.0601026   0.08858066 -0.06796867  0.17787478  0.62739111 -0.02209187\n",
      "  0.1085875 ]\n",
      "[-0.03577731  0.00586404 -0.06428932  0.22224824  0.6608169  -0.01933299\n",
      "  0.25696362]\n",
      "[-0.02763719  0.03173048 -0.05599671  0.04675769  0.6990628  -0.00259533\n",
      "  0.21846683]\n",
      "[ 1.43805913e-03 -3.03458567e-02 -4.08566732e-02  4.02661324e-02\n",
      "  5.45510596e-01  1.77983163e-04  2.68632843e-01]\n",
      "[ 0.00224777 -0.01045014 -0.02300527  0.20712558  0.35361783 -0.00660262\n",
      "  0.22920385]\n",
      "[ 0.0108661   0.06617536 -0.07474523  0.21746228  0.53408184 -0.04202059\n",
      "  0.12721915]\n",
      "[ 0.03108076  0.05976805 -0.09050426  0.21433792  0.62823689 -0.03714788\n",
      "  0.14858446]\n"
     ]
    }
   ],
   "source": [
    "#SP500\n",
    "for j in range(cases):\n",
    "    # row indices of first validation set\n",
    "    v1_ind = np.arange(setindices[holdoutindices[j][0]-1][0]-1,setindices[holdoutindices[j][0]-1][1])\n",
    "    \n",
    "    # row indices of second validation set\n",
    "    v2_ind = np.arange(setindices[holdoutindices[j][1]-1][0]-1,setindices[holdoutindices[j][1]-1][1])\n",
    "    \n",
    "    # row indices of training set\n",
    "    trn_ind = list(set(range(5243))-set(v1_ind)-set(v2_ind))\n",
    "    \n",
    "    # define matrix of features and labels corresponding to first\n",
    "    # validation set\n",
    "    Av1 = A[v1_ind,:]\n",
    "    bv1 = B[v1_ind,1]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to second\n",
    "    # validation set\n",
    "    Av2 = A[v2_ind,:]\n",
    "    bv2 = B[v2_ind,1]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to the \n",
    "    # training set\n",
    "    At = A[trn_ind,:]\n",
    "    bt = B[trn_ind,1]\n",
    "    \n",
    "    Wr = np.zeros((At.shape[1], 26))\n",
    "    \n",
    "    miniEr = 1\n",
    "    miniErIndex = 0\n",
    "    for i in range(26):\n",
    "        #train the data with one of the each lambda and add into Wr\n",
    "        Wr[:,i:i+1] = np.linalg.inv(At.T@At + lam_vals[i]*np.identity(At.shape[1]))@At.T@(bt.reshape(bt.shape[0],1))\n",
    "        bp1 = np.sign(Av1@Wr[:,i])#predicted b\n",
    "        error_vec1 = [0 if bv1[j]==bp1[j] else 1 for j in range(len(bv1))]\n",
    "        er[i] = sum(error_vec1) / len(bv1)\n",
    "        if miniEr > er[i]:\n",
    "            miniEr = er[i]\n",
    "            miniErIndex = i\n",
    "            \n",
    "    #get best lambda from above algorithm         \n",
    "    lambda_b = lam_vals[i]\n",
    "    #get best w from the lambda\n",
    "    w_b = Wr[:,i]\n",
    "    print(w_b)\n",
    "    #calculate predicted label for the second holdout evaluation data\n",
    "    bp2 = np.sign(Av2@w_b)\n",
    "    #calculate the squared error and error rate\n",
    "    er_sq[j] = np.linalg.norm(bp2 - bv2, 2) / len(bv2)\n",
    "    error_vec2 = [0 if bv2[j]==bp2[j] else 1 for j in range(len(bv2))]\n",
    "    er_rate[j] = sum(error_vec2) / len(bv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier based on SP500 index:\n",
      "Square error for each case: \n",
      " [[0.06419924]\n",
      " [0.05852302]\n",
      " [0.05852302]\n",
      " [0.06083322]\n",
      " [0.05752255]\n",
      " [0.06011327]\n",
      " [0.05817189]\n",
      " [0.06178009]]\n",
      "Average square error: \n",
      " 0.05995828580623616\n",
      "Error rate for each case: \n",
      " [[0.54095238]\n",
      " [0.44952381]\n",
      " [0.44952381]\n",
      " [0.48571429]\n",
      " [0.43428571]\n",
      " [0.47428571]\n",
      " [0.43822394]\n",
      " [0.50095238]]\n",
      "Average error rate: \n",
      " 0.4716827541827542\n"
     ]
    }
   ],
   "source": [
    "print(\"The classifier based on SP500 index:\")\n",
    "print(\"Square error for each case: \\n\", er_sq)\n",
    "print(\"Average square error: \\n\", np.mean(er_sq))\n",
    "print(\"Error rate for each case: \\n\", er_rate)\n",
    "print(\"Average error rate: \\n\", np.mean(er_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.07281958  0.08470219 -0.09279638  0.13086581  0.62342648 -0.02060694\n",
      "  0.16042372]\n",
      "[ 0.08692039  0.14263663 -0.14471496  0.1464252   0.57569901 -0.0233818\n",
      "  0.13529384]\n",
      "[-0.00176213  0.06262485 -0.13865532  0.17958439  0.60056109 -0.01778794\n",
      "  0.27280907]\n",
      "[-0.00287209  0.04596075 -0.07082379  0.05785924  0.63872374 -0.00213966\n",
      "  0.23720442]\n",
      "[ 0.02132333 -0.01902649 -0.07005554  0.05913912  0.50066963  0.00528522\n",
      "  0.30016964]\n",
      "[ 0.00968754 -0.00731664 -0.04600602  0.16617721  0.36207705 -0.0090287\n",
      "  0.27860514]\n",
      "[ 0.02858979  0.0795761  -0.0868529   0.17781872  0.51571316 -0.0321661\n",
      "  0.12350818]\n",
      "[ 0.01432264  0.04953983 -0.1178969   0.16015026  0.58589134 -0.03404797\n",
      "  0.24436442]\n"
     ]
    }
   ],
   "source": [
    "#NASDAQ\n",
    "for j in range(cases):\n",
    "    # row indices of first validation set\n",
    "    v1_ind = np.arange(setindices[holdoutindices[j][0]-1][0]-1,setindices[holdoutindices[j][0]-1][1])\n",
    "    \n",
    "    # row indices of second validation set\n",
    "    v2_ind = np.arange(setindices[holdoutindices[j][1]-1][0]-1,setindices[holdoutindices[j][1]-1][1])\n",
    "    \n",
    "    # row indices of training set\n",
    "    trn_ind = list(set(range(5243))-set(v1_ind)-set(v2_ind))\n",
    "    \n",
    "    # define matrix of features and labels corresponding to first\n",
    "    # validation set\n",
    "    Av1 = A[v1_ind,:]\n",
    "    bv1 = B[v1_ind,2]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to second\n",
    "    # validation set\n",
    "    Av2 = A[v2_ind,:]\n",
    "    bv2 = B[v2_ind,2]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to the \n",
    "    # training set\n",
    "    At = A[trn_ind,:]\n",
    "    bt = B[trn_ind,2]\n",
    "    \n",
    "    Wr = np.zeros((At.shape[1], 26))\n",
    "    \n",
    "    miniEr = 1\n",
    "    miniErIndex = 0\n",
    "    for i in range(26):\n",
    "        #train the data with one of the each lambda and add into Wr\n",
    "        Wr[:,i:i+1] = np.linalg.inv(At.T@At + lam_vals[i]*np.identity(At.shape[1]))@At.T@(bt.reshape(bt.shape[0],1))\n",
    "        bp1 = np.sign(Av1@Wr[:,i])#predicted b\n",
    "        error_vec1 = [0 if bv1[j]==bp1[j] else 1 for j in range(len(bv1))]\n",
    "        er[i] = sum(error_vec1) / len(bv1)\n",
    "        if miniEr > er[i]:\n",
    "            miniEr = er[i]\n",
    "            miniErIndex = i\n",
    "            \n",
    "    #get best lambda from above algorithm         \n",
    "    lambda_b = lam_vals[i]\n",
    "    #get best w from the lambda\n",
    "    w_b = Wr[:,i]\n",
    "    print(w_b)\n",
    "    #calculate predicted label for the second holdout evaluation data\n",
    "    bp2 = np.sign(Av2@w_b)\n",
    "    #calculate the squared error and error rate\n",
    "    er_sq[j] = np.linalg.norm(bp2 - bv2, 2) / len(bv2)\n",
    "    error_vec2 = [0 if bv2[j]==bp2[j] else 1 for j in range(len(bv2))]\n",
    "    er_rate[j] = sum(error_vec2) / len(bv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier based on NASDAQ index:\n",
      "Square error for each case: \n",
      " [[0.06305884]\n",
      " [0.06023386]\n",
      " [0.05739626]\n",
      " [0.06142673]\n",
      " [0.0563758 ]\n",
      " [0.05839889]\n",
      " [0.05829988]\n",
      " [0.05987137]]\n",
      "Average square error: \n",
      " 0.05938270415575461\n",
      "Error rate for each case: \n",
      " [[0.52190476]\n",
      " [0.47619048]\n",
      " [0.43238095]\n",
      " [0.4952381 ]\n",
      " [0.41714286]\n",
      " [0.44761905]\n",
      " [0.44015444]\n",
      " [0.47047619]]\n",
      "Average error rate: \n",
      " 0.4626383526383526\n"
     ]
    }
   ],
   "source": [
    "print(\"The classifier based on NASDAQ index:\")\n",
    "print(\"Square error for each case: \\n\", er_sq)\n",
    "print(\"Average square error: \\n\", np.mean(er_sq))\n",
    "print(\"Error rate for each case: \\n\", er_rate)\n",
    "print(\"Average error rate: \\n\", np.mean(er_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
