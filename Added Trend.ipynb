{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5243,)\n",
      "(5243,)\n"
     ]
    }
   ],
   "source": [
    "#setup data\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#define risk free rate(rfr) as the three month treasure yield (DGS3MO)\n",
    "rfr = np.array((5244,1))\n",
    "#define term spread as 10 year treasure interest(DGS10) minus 1 year treasure interest(DGS1)\n",
    "ts = np.array((5244,1))\n",
    "#define default spread as the yield gap between AAA(DAAA) and BBB(DBAA) grade bonds\n",
    "ds = np.array((5244,1))\n",
    "ones = np.ones((5243,1))[:,0]\n",
    "\n",
    "data1 = pd.read_csv('spread.csv')\n",
    "data2 = pd.read_csv('StockMarket.csv')\n",
    "data = pd.merge(data1, data2, on='Date')\n",
    "rfr = data['DGS3MO']\n",
    "ds = data['DGS10'] - data['DGS1']\n",
    "ts = data['DBAA'] - data['DAAA']\n",
    "# print(rfr.shape)\n",
    "# print(ds.shape)\n",
    "# print(ts.shape)\n",
    "# print(ones.shape)\n",
    "# A = np.stack((rfr, ds, ts, ones), axis = 1)\n",
    "\n",
    "rfr2=np.zeros((5243,))\n",
    "ds2=np.zeros((5243,))\n",
    "ts2=np.zeros((5243,))\n",
    "for i in range(5243):\n",
    "    rfr2[i] = rfr[i+1]-rfr[i]\n",
    "    ds2[i] = ds[i+1]-ds[i]\n",
    "    ts2[i] = ts[i+1]-ts[i]\n",
    "#delete the last data since there is no label for the next day\n",
    "# print(data)\n",
    "print(rfr[1:].shape)\n",
    "print(rfr2.shape)\n",
    "A = np.stack((rfr[1:], ds[1:], ts[1:], rfr2, ds2, ts2, ones), axis = 1)\n",
    "# print(A)\n",
    "\n",
    "#the yield of three major index: Dow Jones, SP 500 and Nasdaq\n",
    "B_raw = np.stack((data['DJIA'], data['SP500'], data['NASDAQ']), axis = 1)\n",
    "#Labeled as -1 if the market loss the next day, +1 otherwise \n",
    "B = np.zeros((5244, 3))\n",
    "for i in range(5244):\n",
    "    for j in range(3):\n",
    "        B[i][j] = -1 if B_raw[i][j] < 0 else 1\n",
    "\n",
    "#delete first label since there is no previous day data to predict\n",
    "B= np.delete(B, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LASSO, this code is copied from previous assignment\n",
    "def ista_solve_hot( A, d, la_array ):\n",
    "    # ista_solve_hot: Iterative soft-thresholding for multiple values of\n",
    "    # lambda with hot start for each case - the converged value for the previous\n",
    "    # value of lambda is used as an initial condition for the current lambda.\n",
    "    # this function solves the minimization problem\n",
    "    # Minimize |Ax-d|_2^2 + lambda*|x|_1 (Lasso regression)\n",
    "    # using iterative soft-thresholding.\n",
    "    max_iter = 10**4\n",
    "    tol = 10**(-3)\n",
    "    tau = 1/np.linalg.norm(A,2)**2\n",
    "    n = A.shape[1]\n",
    "    w = np.zeros((n,1))\n",
    "    num_lam = len(la_array)\n",
    "    X = np.zeros((n, num_lam))\n",
    "    for i, each_lambda in enumerate(la_array):\n",
    "        for j in range(max_iter):\n",
    "            z = w - tau*(A.T@(A@w-d))\n",
    "            w_old = w\n",
    "            w = np.sign(z) * np.clip(np.abs(z)-tau*each_lambda/2, 0, np.inf)\n",
    "            X[:, i:i+1] = w\n",
    "            if np.linalg.norm(w - w_old) < tol:\n",
    "                break\n",
    "    return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  10-fold CV \n",
    "\n",
    "# each row of setindices denotes the starting an ending index for one\n",
    "# partition of the data: 5 sets of 30 samples and 5 sets of 29 samples\n",
    "setindices = [[1,525],[526,1050],[1051,1575],[1576,2100],[2101,2625],[2626,3150],[3151,3675],[3676,4200],[4201,4725],[4726,5243]]\n",
    "\n",
    "# each row of holdoutindices denotes the partitions that are held out from\n",
    "# the training set\n",
    "holdoutindices = [[1,2],[2,3],[3,4],[4,5],[5,6],[7,8],[9,10],[10,1]]\n",
    "\n",
    "cases = len(holdoutindices)\n",
    "\n",
    "lam_vals = [1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1e0, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
    "er_sq = np.zeros((cases,1))\n",
    "er_rate = np.zeros((cases,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00622335  0.00748424 -0.06298393  0.44854078  1.33264424 -0.06600125\n",
      "  0.12611149]\n",
      "[ 0.00352089  0.02139729 -0.05729829  0.06428398  0.17059979 -0.00899731\n",
      "  0.09803289]\n",
      "[-0.02327564 -0.01252086 -0.08165596  0.35767141  0.80323955 -0.03928008\n",
      "  0.19703001]\n",
      "[-0.02358046 -0.01087595 -0.06713428  0.12538808  1.06111729 -0.00898125\n",
      "  0.17935599]\n",
      "[-0.0065878  -0.0191154   0.02623461  0.00815141  0.05398126  0.00113761\n",
      "  0.0676405 ]\n",
      "[ 0.00205571  0.00432494  0.00108593  0.01486555  0.02056401 -0.00103783\n",
      "  0.03904531]\n",
      "[ 0.00582242  0.02070651 -0.01519199  0.01288277  0.02524496 -0.00232595\n",
      "  0.01487978]\n",
      "[-0.00665227 -0.00532629 -0.06465436  0.36127985  0.84489999 -0.06485773\n",
      "  0.14752798]\n"
     ]
    }
   ],
   "source": [
    "# DJIA\n",
    "for j in range(cases):\n",
    "    # row indices of first validation set\n",
    "    v1_ind = np.arange(setindices[holdoutindices[j][0]-1][0]-1,setindices[holdoutindices[j][0]-1][1])\n",
    "    \n",
    "    # row indices of second validation set\n",
    "    v2_ind = np.arange(setindices[holdoutindices[j][1]-1][0]-1,setindices[holdoutindices[j][1]-1][1])\n",
    "    \n",
    "    # row indices of training set\n",
    "    trn_ind = list(set(range(5243))-set(v1_ind)-set(v2_ind))\n",
    "    \n",
    "    # define matrix of features and labels corresponding to first\n",
    "    # validation set\n",
    "    Av1 = A[v1_ind,:]\n",
    "    Bv1 = B[v1_ind,:]\n",
    "   \n",
    "    # define matrix of features and labels corresponding to second\n",
    "    # validation set\n",
    "    Av2 = A[v2_ind,:]\n",
    "    Bv2 = B[v2_ind,:]\n",
    "    \n",
    "    \n",
    "    # define matrix of features and labels corresponding to the \n",
    "    # training set\n",
    "    At = A[trn_ind,:]\n",
    "    Bt = B[trn_ind,:]\n",
    "    \n",
    "    # Use training data to learn classifierA\n",
    "    W = ista_solve_hot(At,Bt[:,0].reshape((Bt.shape[0],1)),lam_vals)\n",
    "  \n",
    "    #calculate error in the 26 w coresponding to each lambda\n",
    "    er = np.zeros((26, 1))#error of the 26 lambda cases\n",
    "    miniEr = 1\n",
    "    miniErIndex = 0\n",
    "    for i in range(26):\n",
    "        Bp1 = np.sign(Av1@W[:,i])#predicted b\n",
    "        error_vec1 = [0 if Bv1[j][0]==Bp1[j] else 1 for j in range(len(Bv1))]\n",
    "        er[i] = sum(error_vec1) / len(Bv1)\n",
    "        #select the best lambda with the least error rate\n",
    "        if miniEr > er[i]:\n",
    "            miniEr = er[i]\n",
    "            miniErIndex = i\n",
    "            \n",
    "    #get best lambda from above algorithm\n",
    "    lambda_b = lam_vals[miniErIndex]\n",
    "    #get best w from the lambda\n",
    "    w_b = W[:,miniErIndex]\n",
    "    print(w_b)\n",
    "    #calculate predicted label for the second holdout evaluation data\n",
    "    Bp2 = np.sign(Av2@w_b)\n",
    "    #calculate the squared error and error rate\n",
    "    er_sq[j] = np.linalg.norm(Bp2 - Bv2[:,0], 2) / len(Bv2[:,0])\n",
    "    error_vec2 = [0 if Bv2[j][0]==Bp2[j] else 1 for j in range(len(Bv2[:,0]))]\n",
    "    er_rate[j] = sum(error_vec2) / len(Bv2[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier based on Dow Jones index:\n",
      "Square error for each case: \n",
      " [[0.06166253]\n",
      " [0.06047432]\n",
      " [0.0593846 ]\n",
      " [0.06166253]\n",
      " [0.0572697 ]\n",
      " [0.06011327]\n",
      " [0.05842759]\n",
      " [0.06095238]]\n",
      "Average square error: \n",
      " 0.059993364752731565\n",
      "Error rate for each case: \n",
      " [[0.49904762]\n",
      " [0.48      ]\n",
      " [0.46285714]\n",
      " [0.49904762]\n",
      " [0.43047619]\n",
      " [0.47428571]\n",
      " [0.44208494]\n",
      " [0.48761905]]\n",
      "Average error rate: \n",
      " 0.47192728442728443\n"
     ]
    }
   ],
   "source": [
    "print(\"The classifier based on Dow Jones index:\")\n",
    "print(\"Square error for each case: \\n\", er_sq)\n",
    "print(\"Average square error: \\n\", np.mean(er_sq))\n",
    "print(\"Error rate for each case: \\n\", er_rate)\n",
    "print(\"Average error rate: \\n\", np.mean(er_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01052032  0.01576843 -0.04056527  0.3919773   1.16270601 -0.05399882\n",
      "  0.10034759]\n",
      "[ 7.79965554e-05  1.85161882e-02 -2.08309543e-02  4.32732335e-02\n",
      "  1.21563353e-01 -6.70790810e-03  7.72016552e-02]\n",
      "[-0.03217901 -0.0241027  -0.04964507  0.28228847  0.63968615 -0.03037784\n",
      "  0.19712448]\n",
      "[-0.02984147 -0.01072604 -0.0798663   0.07627019  0.74562989 -0.00915334\n",
      "  0.20502757]\n",
      "[-0.01119385 -0.0156333   0.02959756  0.0051832   0.04826081 -0.0007625\n",
      "  0.07528695]\n",
      "[-0.00145163  0.00461927  0.01158064  0.01232175  0.01699851 -0.00105699\n",
      "  0.03991363]\n",
      "[ 0.00139437  0.02056817  0.00593299  0.00279186  0.00570833 -0.00056546\n",
      "  0.01104221]\n",
      "[-0.01232209 -0.01015915 -0.04721124  0.26606435  0.62321137 -0.05095359\n",
      "  0.15582105]\n"
     ]
    }
   ],
   "source": [
    "# SP500\n",
    "for j in range(cases):\n",
    "    # row indices of first validation set\n",
    "    v1_ind = np.arange(setindices[holdoutindices[j][0]-1][0]-1,setindices[holdoutindices[j][0]-1][1])\n",
    "    \n",
    "    # row indices of second validation set\n",
    "    v2_ind = np.arange(setindices[holdoutindices[j][1]-1][0]-1,setindices[holdoutindices[j][1]-1][1])\n",
    "    \n",
    "    # row indices of training set\n",
    "    trn_ind = list(set(range(5243))-set(v1_ind)-set(v2_ind))\n",
    "    \n",
    "    # define matrix of features and labels corresponding to first\n",
    "    # validation set\n",
    "    Av1 = A[v1_ind,:]\n",
    "    Bv1 = B[v1_ind,:]\n",
    "   \n",
    "    # define matrix of features and labels corresponding to second\n",
    "    # validation set\n",
    "    Av2 = A[v2_ind,:]\n",
    "    Bv2 = B[v2_ind,:]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to the \n",
    "    # training set\n",
    "    At = A[trn_ind,:]\n",
    "    Bt = B[trn_ind,:]\n",
    "\n",
    "    # Use training data to learn classifierA\n",
    "    W = ista_solve_hot(At,Bt[:,1].reshape((Bt.shape[0],1)),lam_vals)\n",
    "  \n",
    "    #calculate error in the 26 w coresponding to each lambda\n",
    "    er = np.zeros((26, 1))#error of the 26 lambda cases\n",
    "    miniEr = 1\n",
    "    miniErIndex = 0\n",
    "    for i in range(26):\n",
    "        Bp1 = np.sign(Av1@W[:,i])#predicted b\n",
    "        error_vec1 = [0 if Bv1[j][0]==Bp1[j] else 1 for j in range(len(Bv1))]\n",
    "        er[i] = sum(error_vec1) / len(Bv1)\n",
    "        #select the best lambda with the least error rate\n",
    "        if miniEr > er[i]:\n",
    "            miniEr = er[i]\n",
    "            miniErIndex = i\n",
    "            \n",
    "    #get best lambda from above algorithm         \n",
    "    lambda_b = lam_vals[miniErIndex]\n",
    "    #get best w from the lambda\n",
    "    w_b = W[:,miniErIndex]\n",
    "    print(w_b)\n",
    "    #calculate predicted label for the second holdout evaluation data\n",
    "    Bp2 = np.sign(Av2@w_b)\n",
    "    #calculate the squared error and error rate\n",
    "    er_sq[j] = np.linalg.norm(Bp2 - Bv2[:,1], 2) / len(Bv2[:,1])\n",
    "    error_vec2 = [0 if Bv2[j][1]==Bp2[j] else 1 for j in range(len(Bv2[:,1]))]\n",
    "    er_rate[j] = sum(error_vec2) / len(Bv2[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier based on SP500 index:\n",
      "Square error for each case: \n",
      " [[0.06385926]\n",
      " [0.05852302]\n",
      " [0.06189744]\n",
      " [0.06178009]\n",
      " [0.05752255]\n",
      " [0.06011327]\n",
      " [0.05817189]\n",
      " [0.06142673]]\n",
      "Average square error: \n",
      " 0.06041177935640187\n",
      "Error rate for each case: \n",
      " [[0.5352381 ]\n",
      " [0.44952381]\n",
      " [0.50285714]\n",
      " [0.50095238]\n",
      " [0.43428571]\n",
      " [0.47428571]\n",
      " [0.43822394]\n",
      " [0.4952381 ]]\n",
      "Average error rate: \n",
      " 0.4788256113256113\n"
     ]
    }
   ],
   "source": [
    "print(\"The classifier based on SP500 index:\")\n",
    "print(\"Square error for each case: \\n\", er_sq)\n",
    "print(\"Average square error: \\n\", np.mean(er_sq))\n",
    "print(\"Error rate for each case: \\n\", er_rate)\n",
    "print(\"Average error rate: \\n\", np.mean(er_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00346617 -0.         -0.05003281  0.26203981  0.95644185 -0.0388952\n",
      "  0.15962068]\n",
      "[ 0.0083704   0.0389152  -0.04182081  0.03197938  0.09876892 -0.00552093\n",
      "  0.07675866]\n",
      "[-0.02169674 -0.00221891 -0.07067127  0.14216232  0.36167036 -0.0155103\n",
      "  0.19190425]\n",
      "[-0.02291296 -0.00729486 -0.06895776  0.07368523  0.53326893 -0.00482711\n",
      "  0.19804243]\n",
      "[-0.00636845 -0.01202494  0.02623778  0.00862604  0.04786266  0.00019211\n",
      "  0.08039705]\n",
      "[ 0.00037164  0.00347786  0.0088996   0.01446395  0.02544302 -0.00125735\n",
      "  0.05448743]\n",
      "[ 0.0053073   0.02301317  0.00474952  0.00330289  0.0079611  -0.00061439\n",
      "  0.01306129]\n",
      "[-0.01911862 -0.01731654 -0.05345111  0.14087632  0.40974279 -0.02677427\n",
      "  0.19481236]\n"
     ]
    }
   ],
   "source": [
    "# NASDAQ\n",
    "for j in range(cases):\n",
    "    # row indices of first validation set\n",
    "    v1_ind = np.arange(setindices[holdoutindices[j][0]-1][0]-1,setindices[holdoutindices[j][0]-1][1])\n",
    "    \n",
    "    # row indices of second validation set\n",
    "    v2_ind = np.arange(setindices[holdoutindices[j][1]-1][0]-1,setindices[holdoutindices[j][1]-1][1])\n",
    "    \n",
    "    # row indices of training set\n",
    "    trn_ind = list(set(range(5243))-set(v1_ind)-set(v2_ind))\n",
    "    \n",
    "    # define matrix of features and labels corresponding to first\n",
    "    # validation set\n",
    "    Av1 = A[v1_ind,:]\n",
    "    Bv1 = B[v1_ind,:]\n",
    "   \n",
    "    # define matrix of features and labels corresponding to second\n",
    "    # validation set\n",
    "    Av2 = A[v2_ind,:]\n",
    "    Bv2 = B[v2_ind,:]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to the \n",
    "    # training set\n",
    "    At = A[trn_ind,:]\n",
    "    Bt = B[trn_ind,:]\n",
    "\n",
    "    # Use training data to learn classifierA\n",
    "    W = ista_solve_hot(At,Bt[:,2].reshape((Bt.shape[0],1)),lam_vals)\n",
    "    #calculate error in the 26 w coresponding to each lambda\n",
    "    er = np.zeros((26, 1))#error of the 26 lambda cases\n",
    "    miniEr = 1\n",
    "    miniErIndex = 0\n",
    "    for i in range(26):\n",
    "        Bp1 = np.sign(Av1@W[:,i])#predicted b\n",
    "        error_vec1 = [0 if Bv1[j][0]==Bp1[j] else 1 for j in range(len(Bv1))]\n",
    "        er[i] = sum(error_vec1) / len(Bv1)\n",
    "        #select the best lambda with the least error rate\n",
    "        if miniEr > er[i]:\n",
    "            miniEr = er[i]\n",
    "            miniErIndex = i\n",
    "            \n",
    "    #get best lambda from above algorithm         \n",
    "    lambda_b = lam_vals[miniErIndex]\n",
    "    #get best w from the lambda\n",
    "    w_b = W[:,miniErIndex]\n",
    "    print(w_b)\n",
    "    #calculate predicted label for the second holdout evaluation data\n",
    "    Bp2 = np.sign(Av2@w_b)\n",
    "    #calculate the squared error and error rate\n",
    "    er_sq[j] = np.linalg.norm(Bp2 - Bv2[:,2], 2) / len(Bv2[:,2])\n",
    "    error_vec2 = [0 if Bv2[j][2]==Bp2[j] else 1 for j in range(len(Bv2[:,2]))]\n",
    "    er_rate[j] = sum(error_vec2) / len(Bv2[:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier based on Nasdaq index:\n",
      "Square error for each case: \n",
      " [[0.06282828]\n",
      " [0.06023386]\n",
      " [0.0572697 ]\n",
      " [0.06107131]\n",
      " [0.0563758 ]\n",
      " [0.05839889]\n",
      " [0.05829988]\n",
      " [0.05975005]]\n",
      "Average square error: \n",
      " 0.05927847172309655\n",
      "Error rate for each case: \n",
      " [[0.51809524]\n",
      " [0.47619048]\n",
      " [0.43047619]\n",
      " [0.48952381]\n",
      " [0.41714286]\n",
      " [0.44761905]\n",
      " [0.44015444]\n",
      " [0.46857143]]\n",
      "Average error rate: \n",
      " 0.460971685971686\n"
     ]
    }
   ],
   "source": [
    "print(\"The classifier based on Nasdaq index:\")\n",
    "print(\"Square error for each case: \\n\", er_sq)\n",
    "print(\"Average square error: \\n\", np.mean(er_sq))\n",
    "print(\"Error rate for each case: \\n\", er_rate)\n",
    "print(\"Average error rate: \\n\", np.mean(er_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00790176  0.00973381 -0.05868183  0.48155665  1.30885961 -0.07038362\n",
      "  0.11531172]\n",
      "[-0.00470969  0.0066662  -0.07113158  0.50266709  1.18660526 -0.07216789\n",
      "  0.14863353]\n",
      "[-0.02199301 -0.01086906 -0.07587581  0.61194517  1.27117758 -0.07458237\n",
      "  0.1855465 ]\n",
      "[-0.02270681 -0.01004891 -0.05640032  0.21047533  1.42649199 -0.01919035\n",
      "  0.16571154]\n",
      "[-0.02225957 -0.04439101 -0.06742329  0.20770606  1.10367667  0.0236309\n",
      "  0.22524929]\n",
      "[-0.02306692 -0.02840103 -0.05261444  0.56850472  0.8156287  -0.0442079\n",
      "  0.20390316]\n",
      "[-7.53446514e-03  7.10282457e-04 -5.53380542e-02  5.92649228e-01\n",
      "  1.06814628e+00 -1.23992879e-01  1.19473972e-01]\n",
      "[-0.00554202 -0.003821   -0.06080872  0.59643134  1.25578727 -0.11507859\n",
      "  0.13882452]\n"
     ]
    }
   ],
   "source": [
    "#Ridge Regression\n",
    "#Dow Jones\n",
    "for j in range(cases):\n",
    "        # row indices of first validation set\n",
    "    v1_ind = np.arange(setindices[holdoutindices[j][0]-1][0]-1,setindices[holdoutindices[j][0]-1][1])\n",
    "    \n",
    "    # row indices of second validation set\n",
    "    v2_ind = np.arange(setindices[holdoutindices[j][1]-1][0]-1,setindices[holdoutindices[j][1]-1][1])\n",
    "    \n",
    "    # row indices of training set\n",
    "    trn_ind = list(set(range(5243))-set(v1_ind)-set(v2_ind))\n",
    "    \n",
    "    # define matrix of features and labels corresponding to first\n",
    "    # validation set\n",
    "    Av1 = A[v1_ind,:]\n",
    "    bv1 = B[v1_ind,0]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to second\n",
    "    # validation set\n",
    "    Av2 = A[v2_ind,:]\n",
    "    bv2 = B[v2_ind,0]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to the \n",
    "    # training set\n",
    "    At = A[trn_ind,:]\n",
    "    bt = B[trn_ind,0]\n",
    "    \n",
    "\n",
    "    Wr = np.zeros((At.shape[1], 26))\n",
    "    \n",
    "    miniEr = 1\n",
    "    miniErIndex = 0\n",
    "    for i in range(26):\n",
    "        #train the data with one of the each lambda and add into Wr\n",
    "        Wr[:,i:i+1] = np.linalg.inv(At.T@At + lam_vals[i]*np.identity(At.shape[1]))@At.T@(bt.reshape(bt.shape[0],1))\n",
    "        bp1 = np.sign(Av1@Wr[:,i])#predicted b\n",
    "        error_vec1 = [0 if bv1[j]==bp1[j] else 1 for j in range(len(bv1))]\n",
    "        er[i] = sum(error_vec1) / len(bv1)\n",
    "        if miniEr > er[i]:\n",
    "            miniEr = er[i]\n",
    "            miniErIndex = i\n",
    "            \n",
    "    #get best lambda from above algorithm         \n",
    "    lambda_b = lam_vals[i]\n",
    "    #get best w from the lambda\n",
    "    w_b = Wr[:,i]\n",
    "    print(w_b)\n",
    "    #calculate predicted label for the second holdout evaluation data\n",
    "    bp2 = np.sign(Av2@w_b)\n",
    "    #calculate the squared error and error rate\n",
    "    er_sq[j] = np.linalg.norm(bp2 - bv2, 2) / len(bv2)\n",
    "    error_vec2 = [0 if bv2[j]==bp2[j] else 1 for j in range(len(bv2))]\n",
    "    er_rate[j] = sum(error_vec2) / len(bv2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier based on Dow Jones index:\n",
      "Square error for each case: \n",
      " [[0.06178009]\n",
      " [0.05962848]\n",
      " [0.0593846 ]\n",
      " [0.06107131]\n",
      " [0.05153428]\n",
      " [0.06011327]\n",
      " [0.05713764]\n",
      " [0.06224813]]\n",
      "Average square error: \n",
      " 0.05911222640582536\n",
      "Error rate for each case: \n",
      " [[0.50095238]\n",
      " [0.46666667]\n",
      " [0.46285714]\n",
      " [0.48952381]\n",
      " [0.34857143]\n",
      " [0.47428571]\n",
      " [0.42277992]\n",
      " [0.50857143]]\n",
      "Average error rate: \n",
      " 0.4592760617760618\n"
     ]
    }
   ],
   "source": [
    "print(\"The classifier based on Dow Jones index:\")\n",
    "print(\"Square error for each case: \\n\", er_sq)\n",
    "print(\"Average square error: \\n\", np.mean(er_sq))\n",
    "print(\"Error rate for each case: \\n\", er_rate)\n",
    "print(\"Average error rate: \\n\", np.mean(er_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.01155549  0.01708646 -0.03758303  0.46902096  1.25797219 -0.06378074\n",
      "  0.09342229]\n",
      "[-0.00955752  0.00151687 -0.03867826  0.47005158  1.1579174  -0.07468433\n",
      "  0.1379266 ]\n",
      "[-0.03121271 -0.02286926 -0.04525434  0.5876414   1.22190397 -0.07055756\n",
      "  0.18834834]\n",
      "[-0.02971304 -0.01071471 -0.07684232  0.17828151  1.33440053 -0.02418504\n",
      "  0.20183877]\n",
      "[-0.02849359 -0.0434462  -0.07524961  0.13961716  1.00119199 -0.02382292\n",
      "  0.2505138 ]\n",
      "[-0.02818793 -0.03185923 -0.03673293  0.50863434  0.72898398 -0.05006385\n",
      "  0.20836744]\n",
      "[-0.01978227 -0.01336213 -0.04123317  0.55072076  1.02392056 -0.12929662\n",
      "  0.16326784]\n",
      "[-0.01177139 -0.00956077 -0.04463617  0.57040923  1.18790979 -0.11825609\n",
      "  0.15101682]\n"
     ]
    }
   ],
   "source": [
    "#SP500\n",
    "for j in range(cases):\n",
    "    # row indices of first validation set\n",
    "    v1_ind = np.arange(setindices[holdoutindices[j][0]-1][0]-1,setindices[holdoutindices[j][0]-1][1])\n",
    "    \n",
    "    # row indices of second validation set\n",
    "    v2_ind = np.arange(setindices[holdoutindices[j][1]-1][0]-1,setindices[holdoutindices[j][1]-1][1])\n",
    "    \n",
    "    # row indices of training set\n",
    "    trn_ind = list(set(range(5243))-set(v1_ind)-set(v2_ind))\n",
    "    \n",
    "    # define matrix of features and labels corresponding to first\n",
    "    # validation set\n",
    "    Av1 = A[v1_ind,:]\n",
    "    bv1 = B[v1_ind,1]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to second\n",
    "    # validation set\n",
    "    Av2 = A[v2_ind,:]\n",
    "    bv2 = B[v2_ind,1]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to the \n",
    "    # training set\n",
    "    At = A[trn_ind,:]\n",
    "    bt = B[trn_ind,1]\n",
    "    \n",
    "    Wr = np.zeros((At.shape[1], 26))\n",
    "    \n",
    "    miniEr = 1\n",
    "    miniErIndex = 0\n",
    "    for i in range(26):\n",
    "        #train the data with one of the each lambda and add into Wr\n",
    "        Wr[:,i:i+1] = np.linalg.inv(At.T@At + lam_vals[i]*np.identity(At.shape[1]))@At.T@(bt.reshape(bt.shape[0],1))\n",
    "        bp1 = np.sign(Av1@Wr[:,i])#predicted b\n",
    "        error_vec1 = [0 if bv1[j]==bp1[j] else 1 for j in range(len(bv1))]\n",
    "        er[i] = sum(error_vec1) / len(bv1)\n",
    "        if miniEr > er[i]:\n",
    "            miniEr = er[i]\n",
    "            miniErIndex = i\n",
    "            \n",
    "    #get best lambda from above algorithm         \n",
    "    lambda_b = lam_vals[i]\n",
    "    #get best w from the lambda\n",
    "    w_b = Wr[:,i]\n",
    "    print(w_b)\n",
    "    #calculate predicted label for the second holdout evaluation data\n",
    "    bp2 = np.sign(Av2@w_b)\n",
    "    #calculate the squared error and error rate\n",
    "    er_sq[j] = np.linalg.norm(bp2 - bv2, 2) / len(bv2)\n",
    "    error_vec2 = [0 if bv2[j]==bp2[j] else 1 for j in range(len(bv2))]\n",
    "    er_rate[j] = sum(error_vec2) / len(bv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier based on SP500 index:\n",
      "Square error for each case: \n",
      " [[0.06363159]\n",
      " [0.05814986]\n",
      " [0.06154474]\n",
      " [0.06119001]\n",
      " [0.05153428]\n",
      " [0.06011327]\n",
      " [0.05791506]\n",
      " [0.06305884]]\n",
      "Average square error: \n",
      " 0.059642206949073365\n",
      "Error rate for each case: \n",
      " [[0.53142857]\n",
      " [0.44380952]\n",
      " [0.49714286]\n",
      " [0.49142857]\n",
      " [0.34857143]\n",
      " [0.47428571]\n",
      " [0.43436293]\n",
      " [0.52190476]]\n",
      "Average error rate: \n",
      " 0.46786679536679543\n"
     ]
    }
   ],
   "source": [
    "print(\"The classifier based on SP500 index:\")\n",
    "print(\"Square error for each case: \\n\", er_sq)\n",
    "print(\"Average square error: \\n\", np.mean(er_sq))\n",
    "print(\"Error rate for each case: \\n\", er_rate)\n",
    "print(\"Average error rate: \\n\", np.mean(er_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.00258208  0.00156134 -0.04740868  0.38442053  1.20617328 -0.05821719\n",
      "  0.15224698]\n",
      "[-0.00313069  0.01904492 -0.06580196  0.41608266  1.10658681 -0.07189426\n",
      "  0.15161355]\n",
      "[-0.02290634 -0.00473378 -0.07081173  0.50605179  1.14441854 -0.06089941\n",
      "  0.19790121]\n",
      "[-0.02421108 -0.00875162 -0.08019888  0.22217647  1.25698172 -0.01803773\n",
      "  0.21352399]\n",
      "[-0.0241653  -0.03978544 -0.09208329  0.21034531  0.96874787  0.00157928\n",
      "  0.26925805]\n",
      "[-0.02604991 -0.03162634 -0.04422114  0.4503785   0.78735573 -0.04262816\n",
      "  0.22521648]\n",
      "[-0.01323917 -0.00584977 -0.04392421  0.48695245  1.0315244  -0.10108605\n",
      "  0.15260382]\n",
      "[-0.02054365 -0.01993565 -0.05449986  0.4627919   1.13944959 -0.09244563\n",
      "  0.20283843]\n"
     ]
    }
   ],
   "source": [
    "#NASDAQ\n",
    "for j in range(cases):\n",
    "    # row indices of first validation set\n",
    "    v1_ind = np.arange(setindices[holdoutindices[j][0]-1][0]-1,setindices[holdoutindices[j][0]-1][1])\n",
    "    \n",
    "    # row indices of second validation set\n",
    "    v2_ind = np.arange(setindices[holdoutindices[j][1]-1][0]-1,setindices[holdoutindices[j][1]-1][1])\n",
    "    \n",
    "    # row indices of training set\n",
    "    trn_ind = list(set(range(5243))-set(v1_ind)-set(v2_ind))\n",
    "    \n",
    "    # define matrix of features and labels corresponding to first\n",
    "    # validation set\n",
    "    Av1 = A[v1_ind,:]\n",
    "    bv1 = B[v1_ind,2]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to second\n",
    "    # validation set\n",
    "    Av2 = A[v2_ind,:]\n",
    "    bv2 = B[v2_ind,2]\n",
    "    \n",
    "    # define matrix of features and labels corresponding to the \n",
    "    # training set\n",
    "    At = A[trn_ind,:]\n",
    "    bt = B[trn_ind,2]\n",
    "    \n",
    "    Wr = np.zeros((At.shape[1], 26))\n",
    "    \n",
    "    miniEr = 1\n",
    "    miniErIndex = 0\n",
    "    for i in range(26):\n",
    "        #train the data with one of the each lambda and add into Wr\n",
    "        Wr[:,i:i+1] = np.linalg.inv(At.T@At + lam_vals[i]*np.identity(At.shape[1]))@At.T@(bt.reshape(bt.shape[0],1))\n",
    "        bp1 = np.sign(Av1@Wr[:,i])#predicted b\n",
    "        error_vec1 = [0 if bv1[j]==bp1[j] else 1 for j in range(len(bv1))]\n",
    "        er[i] = sum(error_vec1) / len(bv1)\n",
    "        if miniEr > er[i]:\n",
    "            miniEr = er[i]\n",
    "            miniErIndex = i\n",
    "            \n",
    "    #get best lambda from above algorithm         \n",
    "    lambda_b = lam_vals[i]\n",
    "    #get best w from the lambda\n",
    "    w_b = Wr[:,i]\n",
    "    print(w_b)\n",
    "    #calculate predicted label for the second holdout evaluation data\n",
    "    bp2 = np.sign(Av2@w_b)\n",
    "    #calculate the squared error and error rate\n",
    "    er_sq[j] = np.linalg.norm(bp2 - bv2, 2) / len(bv2)\n",
    "    error_vec2 = [0 if bv2[j]==bp2[j] else 1 for j in range(len(bv2))]\n",
    "    er_rate[j] = sum(error_vec2) / len(bv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classifier based on NASDAQ index:\n",
      "Square error for each case: \n",
      " [[0.06248084]\n",
      " [0.06023386]\n",
      " [0.05877047]\n",
      " [0.06059419]\n",
      " [0.05096795]\n",
      " [0.05839889]\n",
      " [0.05791506]\n",
      " [0.06083322]]\n",
      "Average square error: \n",
      " 0.058774309576769795\n",
      "Error rate for each case: \n",
      " [[0.51238095]\n",
      " [0.47619048]\n",
      " [0.45333333]\n",
      " [0.48190476]\n",
      " [0.34095238]\n",
      " [0.44761905]\n",
      " [0.43436293]\n",
      " [0.48571429]]\n",
      "Average error rate: \n",
      " 0.45405727155727155\n"
     ]
    }
   ],
   "source": [
    "print(\"The classifier based on NASDAQ index:\")\n",
    "print(\"Square error for each case: \\n\", er_sq)\n",
    "print(\"Average square error: \\n\", np.mean(er_sq))\n",
    "print(\"Error rate for each case: \\n\", er_rate)\n",
    "print(\"Average error rate: \\n\", np.mean(er_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
